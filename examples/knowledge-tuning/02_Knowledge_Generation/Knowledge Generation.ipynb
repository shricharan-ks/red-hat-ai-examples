{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install SDG\n",
    "```bash \n",
    "git clone https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub.git\n",
    "cd sdg_hub\n",
    "pip install .[examples]\n",
    "```\n",
    "**⚠️ If you haven't already, run the document pre-processing notebook to create the seed data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.knowledge_utils import create_knowledge_regular_ds, create_knowledge_pretraining_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "WORKSPACE = Path.cwd().parent # Path to the workspace directory\n",
    "\n",
    "\n",
    "OUTPUT_DIR= WORKSPACE / \"output\" / \"step_02\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True) # Create the output directory if it doesn't exist\n",
    "\n",
    "\n",
    "SEED_DATA_FILE = WORKSPACE / \"output\" / \"step_01\" / \"final_seed_data.jsonl\" # Path to the seed data file generated in step 1\n",
    "\n",
    "\n",
    "if not SEED_DATA_FILE.exists():\n",
    "    raise FileNotFoundError(f\"\\nNot a valid seed data ! {SEED_DATA_FILE}.\\nPlease run step 1 to generate the seed data. \\n(or) Provide the correct path to the seed data file.\")\n",
    "\n",
    "# CONFIGURE MODEL DETAILS HERE FOR THE FLOW\n",
    "MODEL_NAME = \"openai/llama-4-scout-17b-16e-w4a16\"\n",
    "API_KEY = \"\"   # Provide your API key here\n",
    "ENDPOINT = \"https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Party\n",
    "from datasets import load_dataset\n",
    "\n",
    "# First Party\n",
    "from sdg_hub import Flow, FlowRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to run the flow with async mode\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SDG\n",
    "- This will create knowledge flow from provided yaml file\n",
    "- We will run this on small dataset for demo purposes\n",
    "- For large scale generation, please use the python command provided in the next cell\n",
    "- You can analyze the generated data to ensure the quality is similar to proivded QnA pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover the available generation flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Discovered <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> flows                                                              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">registry.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py#113\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Discovered \u001b[1;36m5\u001b[0m flows                                                              \u001b]8;id=475665;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py\u001b\\\u001b[2mregistry.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=615449;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py#113\u001b\\\u001b[2m113\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Discovered <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> flows                                                              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">registry.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py#113\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Discovered \u001b[1;36m5\u001b[0m flows                                                              \u001b]8;id=4350;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py\u001b\\\u001b[2mregistry.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=604594;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/registry.py#113\u001b\\\u001b[2m113\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> ID               </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Name                  </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Author               </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Tags                  </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Description           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> epic-jade-656    </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Extractive Summary    </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> SDG Hub Contributors </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> knowledge-tuning,     </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Generate extractive   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Knowledge Tuning      </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> document-internaliza… </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> summary from the      </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Dataset Generation    </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> question-generation,  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> input document. Each  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Flow                  </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> knowledge-extractive… </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> document is first     </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> qa-pairs,             </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> converted into list   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> extractive-summaries  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> of knowledge segments </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> for creating          </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> extractive summary    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> and then annotated    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> with context,         </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> relationship and      </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> relevance. This is    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> then converted into   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Question-Answer       </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> pairs.                </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> green-clay-812   </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Structured Text       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> SDG Hub Contributors </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> text-analysis,        </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Multi-step pipeline   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Insights Extraction   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> summarization, nlp,   </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> for extracting        </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Flow                  </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> structured-output,    </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> structured insights   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> insights,             </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> from text including   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> sentiment-analysis,   </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> summary, keywords,    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> entity-extraction,    </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> entities, and         </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> keyword-extraction    </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> sentiment analysis    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> combined into a JSON  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> output                </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> heavy-heart-77   </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Key Facts Knowledge   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> SDG Hub Contributors </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> knowledge-tuning,     </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Generating list of    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Tuning Dataset        </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> document-internaliza… </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> atomic facts from a   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Generation Flow       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> question-generation,  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> document and          </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> qa-pairs, key-facts   </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> converting each       </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> atomic fact into a QA </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> pair. This flow will  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> generate 5 QA pairs   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> for each atomic fact. </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> mild-thunder-748 </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Detailed Summary      </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> SDG Hub Contributors </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> knowledge-tuning,     </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Generates high level  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Knowledge Tuning      </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> document-internaliza… </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> summaries of the      </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Dataset Generation    </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> question-generation,  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> document focusing on  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Flow                  </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> qa-pairs,             </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> overarching themes,   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> detailed-summaries    </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> main arguments, and   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> core principles. This </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> is then converted     </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> into Question-Answer  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> pairs.                </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> small-rock-799   </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Advanced Document     </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> SDG Hub Contributors </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> question-generation,  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> A comprehensive flow  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Grounded              </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> knowledge-extraction, </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> that generates        </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Question-Answer       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> qa-pairs,             </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> high-quality          </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Generation Flow for   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> document-processing,  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> question-answer pairs </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> Knowledge Tuning      </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> educational           </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> from input documents  </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> using multiple LLM    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> blocks for question   </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> generation, answer    </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> synthesis, and        </span>│\n",
       "│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">                  </span>│<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">                       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> quality evaluation.   </span>│\n",
       "└──────────────────┴───────────────────────┴──────────────────────┴───────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;95m \u001b[0m\u001b[1;95mID              \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mName                 \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mAuthor              \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mTags                 \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mDescription          \u001b[0m\u001b[1;95m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[1;95m \u001b[0m\u001b[1;95mepic-jade-656   \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mExtractive Summary   \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mSDG Hub Contributors\u001b[0m\u001b[92m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mknowledge-tuning,    \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mGenerate extractive  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mKnowledge Tuning     \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mdocument-internaliza…\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37msummary from the     \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mDataset Generation   \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mquestion-generation, \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37minput document. Each \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mFlow                 \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mknowledge-extractive…\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mdocument is first    \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mqa-pairs,            \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mconverted into list  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mextractive-summaries \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mof knowledge segments\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mfor creating         \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mextractive summary   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mand then annotated   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mwith context,        \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mrelationship and     \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mrelevance. This is   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mthen converted into  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mQuestion-Answer      \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mpairs.               \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m \u001b[0m\u001b[1;95mgreen-clay-812  \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mStructured Text      \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mSDG Hub Contributors\u001b[0m\u001b[92m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mtext-analysis,       \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mMulti-step pipeline  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mInsights Extraction  \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33msummarization, nlp,  \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mfor extracting       \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mFlow                 \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mstructured-output,   \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mstructured insights  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33minsights,            \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mfrom text including  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33msentiment-analysis,  \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37msummary, keywords,   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mentity-extraction,   \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mentities, and        \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mkeyword-extraction   \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37msentiment analysis   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mcombined into a JSON \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37moutput               \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m \u001b[0m\u001b[1;95mheavy-heart-77  \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mKey Facts Knowledge  \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mSDG Hub Contributors\u001b[0m\u001b[92m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mknowledge-tuning,    \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mGenerating list of   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mTuning Dataset       \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mdocument-internaliza…\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37matomic facts from a  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mGeneration Flow      \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mquestion-generation, \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mdocument and         \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mqa-pairs, key-facts  \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mconverting each      \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37matomic fact into a QA\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mpair. This flow will \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mgenerate 5 QA pairs  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mfor each atomic fact.\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m \u001b[0m\u001b[1;95mmild-thunder-748\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mDetailed Summary     \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mSDG Hub Contributors\u001b[0m\u001b[92m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mknowledge-tuning,    \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mGenerates high level \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mKnowledge Tuning     \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mdocument-internaliza…\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37msummaries of the     \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mDataset Generation   \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mquestion-generation, \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mdocument focusing on \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mFlow                 \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mqa-pairs,            \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37moverarching themes,  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mdetailed-summaries   \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mmain arguments, and  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mcore principles. This\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mis then converted    \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37minto Question-Answer \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mpairs.               \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m \u001b[0m\u001b[1;95msmall-rock-799  \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mAdvanced Document    \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mSDG Hub Contributors\u001b[0m\u001b[92m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mquestion-generation, \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mA comprehensive flow \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mGrounded             \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mknowledge-extraction,\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mthat generates       \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mQuestion-Answer      \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mqa-pairs,            \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mhigh-quality         \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mGeneration Flow for  \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mdocument-processing, \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mquestion-answer pairs\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m \u001b[0m\u001b[1;96mKnowledge Tuning     \u001b[0m\u001b[1;96m \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33meducational          \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mfrom input documents \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37musing multiple LLM   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mblocks for question  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mgeneration, answer   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37msynthesis, and       \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[1;95m                  \u001b[0m│\u001b[1;96m                       \u001b[0m│\u001b[92m                      \u001b[0m│\u001b[33m                       \u001b[0m│\u001b[37m \u001b[0m\u001b[37mquality evaluation.  \u001b[0m\u001b[37m \u001b[0m│\n",
       "└──────────────────┴───────────────────────┴──────────────────────┴───────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available flows: [{'id': 'green-clay-812', 'name': 'Structured Text Insights Extraction Flow'}, {'id': 'small-rock-799', 'name': 'Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning'}, {'id': 'mild-thunder-748', 'name': 'Detailed Summary Knowledge Tuning Dataset Generation Flow'}, {'id': 'heavy-heart-77', 'name': 'Key Facts Knowledge Tuning Dataset Generation Flow'}, {'id': 'epic-jade-656', 'name': 'Extractive Summary Knowledge Tuning Dataset Generation Flow'}]\n",
      "QA flows: [{'id': 'small-rock-799', 'name': 'Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning'}, {'id': 'mild-thunder-748', 'name': 'Detailed Summary Knowledge Tuning Dataset Generation Flow'}, {'id': 'heavy-heart-77', 'name': 'Key Facts Knowledge Tuning Dataset Generation Flow'}, {'id': 'epic-jade-656', 'name': 'Extractive Summary Knowledge Tuning Dataset Generation Flow'}]\n"
     ]
    }
   ],
   "source": [
    "# Auto-discover all available flows (no setup needed!)\n",
    "FlowRegistry.discover_flows()\n",
    "\n",
    "# List available flows\n",
    "flows = FlowRegistry.list_flows()\n",
    "print(f\"Available flows: {flows}\")\n",
    "\n",
    "# You can also search the flows by tag\n",
    "qa_flows = FlowRegistry.search_flows(tag=\"question-generation\")\n",
    "print(f\"QA flows: {qa_flows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading flow from:                                                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#172\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">Generation/.venv/lib/python3.12/site-packages/sdg_hub/flows/qa_generation/document_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">grounded_qa/multi_summary_qa/instructlab/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">flow.yaml</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading flow from:                                                                  \u001b]8;id=757786;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=968237;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35mGeneration/.venv/lib/python3.12/site-packages/sdg_hub/flows/qa_generation/document_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35mgrounded_qa/multi_summary_qa/instructlab/\u001b[0m\u001b[95mflow.yaml\u001b[0m                                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading flow from:                                                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#172\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">Generation/.venv/lib/python3.12/site-packages/sdg_hub/flows/qa_generation/document_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">grounded_qa/multi_summary_qa/instructlab/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">flow.yaml</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading flow from:                                                                  \u001b]8;id=79309;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=319249;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35mGeneration/.venv/lib/python3.12/site-packages/sdg_hub/flows/qa_generation/document_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35mgrounded_qa/multi_summary_qa/instructlab/\u001b[0m\u001b[95mflow.yaml\u001b[0m                                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will use the \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\" flow.\n",
    "# For loading the flow simply use the fullname to load it\n",
    "flow_name = \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\"\n",
    "flow_path = FlowRegistry.get_flow_path(flow_name)\n",
    "flow = Flow.from_yaml(flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the recommended model and set the model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Llama-3.3-70B-Instruct'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow.get_default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': 'meta-llama/Llama-3.3-70B-Instruct',\n",
       " 'compatible': ['microsoft/phi-4', 'mistralai/Mixtral-8x7B-Instruct-v0.1'],\n",
       " 'experimental': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow.get_model_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Auto-detected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> LLM blocks for configuration: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness'</span>,                 <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#864\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">864</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span>,                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question'</span><span style=\"font-weight: bold\">]</span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Auto-detected \u001b[1;36m7\u001b[0m LLM blocks for configuration: \u001b[1m[\u001b[0m\u001b[32m'eval_faithfulness'\u001b[0m,                 \u001b]8;id=269390;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=157395;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#864\u001b\\\u001b[2m864\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'eval_relevancy'\u001b[0m, \u001b[32m'gen_atomic_facts'\u001b[0m, \u001b[32m'gen_detailed_summary'\u001b[0m,                       \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'gen_extractive_summary'\u001b[0m, \u001b[32m'knowledge_generation'\u001b[0m, \u001b[32m'verify_question'\u001b[0m\u001b[1m]\u001b[0m                \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Auto-detected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> LLM blocks for configuration: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness'</span>,                 <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#864\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">864</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span>,                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question'</span><span style=\"font-weight: bold\">]</span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Auto-detected \u001b[1;36m7\u001b[0m LLM blocks for configuration: \u001b[1m[\u001b[0m\u001b[32m'eval_faithfulness'\u001b[0m,                 \u001b]8;id=211357;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=787201;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#864\u001b\\\u001b[2m864\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'eval_relevancy'\u001b[0m, \u001b[32m'gen_atomic_facts'\u001b[0m, \u001b[32m'gen_detailed_summary'\u001b[0m,                       \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'gen_extractive_summary'\u001b[0m, \u001b[32m'knowledge_generation'\u001b[0m, \u001b[32m'verify_question'\u001b[0m\u001b[1m]\u001b[0m                \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=712133;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=976952;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=54011;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=392364;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span> with model                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'gen_detailed_summary'\u001b[0m with model                \u001b]8;id=198543;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=790278;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span> with model                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'gen_detailed_summary'\u001b[0m with model                \u001b]8;id=469555;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=222753;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=160844;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=192455;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=411046;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=939259;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span> with model                    <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'gen_atomic_facts'\u001b[0m with model                    \u001b]8;id=41544;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=324023;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span> with model                    <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'gen_atomic_facts'\u001b[0m with model                    \u001b]8;id=875250;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=35593;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=705925;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=66265;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=916275;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=869169;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span> with model              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'gen_extractive_summary'\u001b[0m with model              \u001b]8;id=721111;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=199351;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span> with model              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'gen_extractive_summary'\u001b[0m with model              \u001b]8;id=555261;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=955623;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=81764;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=80439;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=845065;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=705944;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span> with model                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'knowledge_generation'\u001b[0m with model                \u001b]8;id=413646;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=324498;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span> with model                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'knowledge_generation'\u001b[0m with model                \u001b]8;id=827567;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=956317;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=439556;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=343762;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=788476;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=720465;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness_llm_chat'</span> with model          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'eval_faithfulness_llm_chat'\u001b[0m with model          \u001b]8;id=226052;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=355213;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness_llm_chat'</span> with model          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'eval_faithfulness_llm_chat'\u001b[0m with model          \u001b]8;id=79663;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=798462;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=559050;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464750;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=863281;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=239442;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy_llm_chat'</span> with model             <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'eval_relevancy_llm_chat'\u001b[0m with model             \u001b]8;id=142167;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=868581;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy_llm_chat'</span> with model             <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'eval_relevancy_llm_chat'\u001b[0m with model             \u001b]8;id=609566;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=190150;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=823188;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=396208;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded LLM client for model <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">client_manager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded LLM client for model \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m           \u001b]8;id=585534;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py\u001b\\\u001b[2mclient_manager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=213609;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/client_manager.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question_llm_chat'</span> with model            <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'verify_question_llm_chat'\u001b[0m with model            \u001b]8;id=337132;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=36924;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialized LLMChatBlock <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question_llm_chat'</span> with model            <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized LLMChatBlock \u001b[32m'verify_question_llm_chat'\u001b[0m with model            \u001b]8;id=247645;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=24147;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#265\u001b\\\u001b[2m265\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m                                      \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Successfully configured <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> LLM blocks with: model:                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#903\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">903</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>, api_base:                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-ais</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ervices-bu.com:443/v1'</span>, api_key: 1156ecc8851c8afdfb1011bf114d2ac5                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Successfully configured \u001b[1;36m7\u001b[0m LLM blocks with: model:                                   \u001b]8;id=637896;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=445232;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#903\u001b\\\u001b[2m903\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m, api_base:                                     \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-ais\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mervices-bu.com:443/v1'\u001b[0m, api_key: 1156ecc8851c8afdfb1011bf114d2ac5                   \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Successfully configured <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> LLM blocks with: model:                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#903\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">903</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'openai/llama-4-scout-17b-16e-w4a16'</span>, api_base:                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-ais</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ervices-bu.com:443/v1'</span>, api_key: 1156ecc8851c8afdfb1011bf114d2ac5                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Successfully configured \u001b[1;36m7\u001b[0m LLM blocks with: model:                                   \u001b]8;id=900785;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=949513;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#903\u001b\\\u001b[2m903\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'openai/llama-4-scout-17b-16e-w4a16'\u001b[0m, api_base:                                     \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-ais\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mervices-bu.com:443/v1'\u001b[0m, api_key: 1156ecc8851c8afdfb1011bf114d2ac5                   \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Configured blocks: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span>,      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#906\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">906</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span>,           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question'</span><span style=\"font-weight: bold\">]</span>                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Configured blocks: \u001b[1m[\u001b[0m\u001b[32m'eval_faithfulness'\u001b[0m, \u001b[32m'eval_relevancy'\u001b[0m, \u001b[32m'gen_atomic_facts'\u001b[0m,      \u001b]8;id=876704;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=999848;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#906\u001b\\\u001b[2m906\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'gen_detailed_summary'\u001b[0m, \u001b[32m'gen_extractive_summary'\u001b[0m, \u001b[32m'knowledge_generation'\u001b[0m,           \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'verify_question'\u001b[0m\u001b[1m]\u001b[0m                                                                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Configured blocks: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span>,      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#906\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">906</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span>,           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question'</span><span style=\"font-weight: bold\">]</span>                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Configured blocks: \u001b[1m[\u001b[0m\u001b[32m'eval_faithfulness'\u001b[0m, \u001b[32m'eval_relevancy'\u001b[0m, \u001b[32m'gen_atomic_facts'\u001b[0m,      \u001b]8;id=330368;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=922198;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#906\u001b\\\u001b[2m906\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'gen_detailed_summary'\u001b[0m, \u001b[32m'gen_extractive_summary'\u001b[0m, \u001b[32m'knowledge_generation'\u001b[0m,           \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'verify_question'\u001b[0m\u001b[1m]\u001b[0m                                                                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can dynamically change the model without having to change the flow yaml file.\n",
    "# Configure the flow to use a vllm model hosted at localhost:8000/v1. \n",
    "flow.set_model_config(\n",
    "    model=MODEL_NAME,\n",
    "    api_base=ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seed data\n",
    "number_of_samples = 2\n",
    "\n",
    "ds = load_dataset('json', data_files=f\"{SEED_DATA_FILE}\", split='train')\n",
    "ds = ds.shuffle(seed=42).select(range(number_of_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting flow <span style=\"color: #008000; text-decoration-color: #008000\">'Advanced Document Grounded Question-Answer Generation Flow for </span>      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#515\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">515</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tuning'</span> v1.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples across <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> blocks                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting flow \u001b[32m'Advanced Document Grounded Question-Answer Generation Flow for \u001b[0m      \u001b]8;id=525683;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=297260;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#515\u001b\\\u001b[2m515\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mKnowledge Tuning'\u001b[0m v1.\u001b[1;36m0.0\u001b[0m with \u001b[1;36m2\u001b[0m samples across \u001b[1;36m18\u001b[0m blocks                            \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting flow <span style=\"color: #008000; text-decoration-color: #008000\">'Advanced Document Grounded Question-Answer Generation Flow for </span>      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#515\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">515</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tuning'</span> v1.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples across <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> blocks                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting flow \u001b[32m'Advanced Document Grounded Question-Answer Generation Flow for \u001b[0m      \u001b]8;id=341260;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=538418;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#515\u001b\\\u001b[2m515\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mKnowledge Tuning'\u001b[0m v1.\u001b[1;36m0.0\u001b[0m with \u001b[1;36m2\u001b[0m samples across \u001b[1;36m18\u001b[0m blocks                            \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: duplicate_document_col <span style=\"font-weight: bold\">(</span>DuplicateColumnsBlock<span style=\"font-weight: bold\">)</span>                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m1\u001b[0m/\u001b[1;36m18\u001b[0m: duplicate_document_col \u001b[1m(\u001b[0mDuplicateColumnsBlock\u001b[1m)\u001b[0m                \u001b]8;id=315006;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149927;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: duplicate_document_col <span style=\"font-weight: bold\">(</span>DuplicateColumnsBlock<span style=\"font-weight: bold\">)</span>                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m1\u001b[0m/\u001b[1;36m18\u001b[0m: duplicate_document_col \u001b[1m(\u001b[0mDuplicateColumnsBlock\u001b[1m)\u001b[0m                \u001b]8;id=746620;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=110332;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">duplicate_document_col</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: DuplicateColumnsBlock</span>                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 11</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3</span>                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: base_document</span>                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mduplicate_document_col\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: DuplicateColumnsBlock\u001b[0m                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 11\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3\u001b[0m                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: base_document\u001b[0m                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">duplicate_document_col - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 11 → 12</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: base_document</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mduplicate_document_col - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 11 → 12\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: base_document\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3\u001b[0m                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'duplicate_document_col'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> columns        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'duplicate_document_col'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m12\u001b[0m columns        \u001b]8;id=254523;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=11131;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'duplicate_document_col'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> columns        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'duplicate_document_col'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m12\u001b[0m columns        \u001b]8;id=282444;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=182140;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: detailed_summary_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m2\u001b[0m/\u001b[1;36m18\u001b[0m: detailed_summary_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m                  \u001b]8;id=664727;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=365463;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: detailed_summary_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m2\u001b[0m/\u001b[1;36m18\u001b[0m: detailed_summary_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m                  \u001b]8;id=591667;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=377448;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">detailed_summary_prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: PromptBuilderBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 12</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document</span>                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: summary_prompt</span>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mdetailed_summary_prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: PromptBuilderBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 12\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document\u001b[0m                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: summary_prompt\u001b[0m                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">detailed_summary_prompt - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 12 → 13</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: summary_prompt</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, summary_prompt</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mdetailed_summary_prompt - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 12 → 13\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: summary_prompt\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, summary_prompt\u001b[0m                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'detailed_summary_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> columns       <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'detailed_summary_prompt'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m13\u001b[0m columns       \u001b]8;id=123725;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625703;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'detailed_summary_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> columns       <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'detailed_summary_prompt'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m13\u001b[0m columns       \u001b]8;id=840966;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=521562;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: gen_detailed_summary <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m3\u001b[0m/\u001b[1;36m18\u001b[0m: gen_detailed_summary \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                           \u001b]8;id=56059;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=956505;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: gen_detailed_summary <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m3\u001b[0m/\u001b[1;36m18\u001b[0m: gen_detailed_summary \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                           \u001b]8;id=750263;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=674640;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">gen_detailed_summary</span><span style=\"color: #000080; text-decoration-color: #000080\"> ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: LLMChatBlock</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 13</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt</span>                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: raw_summary_detailed</span>                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mgen_detailed_summary\u001b[0m\u001b[34m \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: LLMChatBlock\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 13\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt\u001b[0m                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: raw_summary_detailed\u001b[0m                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m2\u001b[0m samples                                   \u001b]8;id=372732;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=102990;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m2\u001b[0m samples                                   \u001b]8;id=324549;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625353;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:17 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:17 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=891918;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=66156;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=899040;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=197587;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m2\u001b[0m samples                           \u001b]8;id=337729;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=938838;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m2\u001b[0m samples                           \u001b]8;id=109060;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=356029;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">gen_detailed_summary - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 13 → 14</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_summary_detailed</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, raw_summary_detailed, summary_prompt</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mgen_detailed_summary - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 13 → 14\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_summary_detailed\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, raw_summary_detailed, summary_prompt\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> columns          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'gen_detailed_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m14\u001b[0m columns          \u001b]8;id=239351;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=624111;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'gen_detailed_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> columns          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'gen_detailed_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m14\u001b[0m columns          \u001b]8;id=944014;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=222125;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_detailed_summary <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m4\u001b[0m/\u001b[1;36m18\u001b[0m: parse_detailed_summary \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                      \u001b]8;id=99449;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=741527;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_detailed_summary <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m4\u001b[0m/\u001b[1;36m18\u001b[0m: parse_detailed_summary \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                      \u001b]8;id=156318;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803103;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">parse_detailed_summary</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: TextParserBlock</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 14</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed</span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: summary_detailed</span>                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mparse_detailed_summary\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: TextParserBlock\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 14\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed\u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: summary_detailed\u001b[0m                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">parse_detailed_summary - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 14 → 15</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: summary_detailed</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, raw_summary_detailed, </span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, summary_prompt</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mparse_detailed_summary - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 14 → 15\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: summary_detailed\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: base_document, document, document_outline, document_title, domain, icl_document, icl_query_1,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, raw_summary_detailed, \u001b[0m                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37msummary_detailed, summary_prompt\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_detailed_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> columns        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_detailed_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m15\u001b[0m columns        \u001b]8;id=680468;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=644135;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_detailed_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> columns        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_detailed_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m15\u001b[0m columns        \u001b]8;id=850095;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=56262;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: atomic_facts_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m5\u001b[0m/\u001b[1;36m18\u001b[0m: atomic_facts_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m                      \u001b]8;id=625128;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=545525;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: atomic_facts_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m5\u001b[0m/\u001b[1;36m18\u001b[0m: atomic_facts_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m                      \u001b]8;id=471051;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=243751;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">atomic_facts_prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: PromptBuilderBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 15</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed</span>                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: atomic_facts_prompt</span>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34matomic_facts_prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: PromptBuilderBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 15\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37msummary_detailed\u001b[0m                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: atomic_facts_prompt\u001b[0m                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 244.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">atomic_facts_prompt - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ─────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 15 → 16</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: atomic_facts_prompt</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_summary_detailed, summary_detailed, summary_prompt</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32matomic_facts_prompt - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 15 → 16\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: atomic_facts_prompt\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_summary_detailed, summary_detailed, summary_prompt\u001b[0m                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:23] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'atomic_facts_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> columns           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'atomic_facts_prompt'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m16\u001b[0m columns           \u001b]8;id=4849;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=119243;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:23] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'atomic_facts_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> columns           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'atomic_facts_prompt'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m16\u001b[0m columns           \u001b]8;id=601259;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=93445;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: gen_atomic_facts <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                               <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m6\u001b[0m/\u001b[1;36m18\u001b[0m: gen_atomic_facts \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                               \u001b]8;id=177252;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=233349;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: gen_atomic_facts <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                               <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m6\u001b[0m/\u001b[1;36m18\u001b[0m: gen_atomic_facts \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                               \u001b]8;id=613929;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=669682;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">gen_atomic_facts</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: LLMChatBlock</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 16</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, atomic_facts_prompt</span>                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: raw_atomic_facts</span>                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mgen_atomic_facts\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: LLMChatBlock\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 16\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37msummary_detailed, atomic_facts_prompt\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: raw_atomic_facts\u001b[0m                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:23] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m2\u001b[0m samples                                   \u001b]8;id=964965;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=430473;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m2\u001b[0m samples                                   \u001b]8;id=191983;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=455808;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:23 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:23 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=685916;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=46451;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=832793;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=477969;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m2\u001b[0m samples                           \u001b]8;id=518890;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=541310;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m2\u001b[0m samples                           \u001b]8;id=374461;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=475480;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">gen_atomic_facts - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 16 → 17</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_atomic_facts</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_atomic_facts, raw_summary_detailed, summary_detailed, summary_prompt</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mgen_atomic_facts - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 16 → 17\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_atomic_facts\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_atomic_facts, raw_summary_detailed, summary_detailed, summary_prompt\u001b[0m                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> columns              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'gen_atomic_facts'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m17\u001b[0m columns              \u001b]8;id=248650;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=328226;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'gen_atomic_facts'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> columns              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'gen_atomic_facts'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m17\u001b[0m columns              \u001b]8;id=302369;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=530906;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_atomic_facts <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m7\u001b[0m/\u001b[1;36m18\u001b[0m: parse_atomic_facts \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                          \u001b]8;id=120916;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=404195;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_atomic_facts <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m7\u001b[0m/\u001b[1;36m18\u001b[0m: parse_atomic_facts \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                          \u001b]8;id=796590;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=734501;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">parse_atomic_facts</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: TextParserBlock</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 17</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, atomic_facts_prompt, raw_atomic_facts</span>                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: summary_atomic_facts</span>                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mparse_atomic_facts\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: TextParserBlock\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 17\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37msummary_detailed, atomic_facts_prompt, raw_atomic_facts\u001b[0m                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: summary_atomic_facts\u001b[0m                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">parse_atomic_facts - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ─────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 17 → 18</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: summary_atomic_facts</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_atomic_facts, raw_summary_detailed, summary_atomic_facts, summary_detailed, summary_prompt</span>                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mparse_atomic_facts - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 17 → 18\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: summary_atomic_facts\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_atomic_facts, raw_summary_detailed, summary_atomic_facts, summary_detailed, summary_prompt\u001b[0m                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_atomic_facts'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> columns            <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_atomic_facts'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m18\u001b[0m columns            \u001b]8;id=329895;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=961465;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_atomic_facts'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> columns            <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_atomic_facts'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m18\u001b[0m columns            \u001b]8;id=298349;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=851562;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: extractive_summary_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m8\u001b[0m/\u001b[1;36m18\u001b[0m: extractive_summary_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m                \u001b]8;id=391138;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=327425;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: extractive_summary_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m8\u001b[0m/\u001b[1;36m18\u001b[0m: extractive_summary_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m                \u001b]8;id=232349;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=671120;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">extractive_summary_prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: PromptBuilderBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 18</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts</span>                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: extractive_summary_prompt</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mextractive_summary_prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: PromptBuilderBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 18\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37msummary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts\u001b[0m                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: extractive_summary_prompt\u001b[0m                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 258.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">extractive_summary_prompt - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 18 → 19</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: extractive_summary_prompt</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, raw_atomic_facts, raw_summary_detailed, summary_atomic_facts, summary_detailed, summary_prompt</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mextractive_summary_prompt - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 18 → 19\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: extractive_summary_prompt\u001b[0m                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, raw_atomic_facts, raw_summary_detailed, summary_atomic_facts, summary_detailed, summary_prompt\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'extractive_summary_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> columns     <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'extractive_summary_prompt'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m19\u001b[0m columns     \u001b]8;id=901475;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=271352;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'extractive_summary_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> columns     <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'extractive_summary_prompt'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m19\u001b[0m columns     \u001b]8;id=483613;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=430150;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: gen_extractive_summary <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                         <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m9\u001b[0m/\u001b[1;36m18\u001b[0m: gen_extractive_summary \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                         \u001b]8;id=742160;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=339810;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: gen_extractive_summary <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                         <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m9\u001b[0m/\u001b[1;36m18\u001b[0m: gen_extractive_summary \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                         \u001b]8;id=716639;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=684779;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">gen_extractive_summary</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: LLMChatBlock</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 19</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts, extractive_summary_prompt</span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: raw_summary_extractive</span>                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mgen_extractive_summary\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: LLMChatBlock\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 19\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37msummary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts, extractive_summary_prompt\u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: raw_summary_extractive\u001b[0m                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m2\u001b[0m samples                                   \u001b]8;id=428549;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=191821;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m2\u001b[0m samples                                   \u001b]8;id=204280;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=951527;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:27 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:27 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=623076;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=229402;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=431461;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=475515;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m2\u001b[0m samples                           \u001b]8;id=281882;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=524593;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m2\u001b[0m samples                           \u001b]8;id=101725;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=64182;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">gen_extractive_summary - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 19 → 20</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_summary_extractive</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, raw_atomic_facts, raw_summary_detailed, raw_summary_extractive, summary_atomic_facts, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, summary_prompt</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mgen_extractive_summary - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 19 → 20\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_summary_extractive\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, raw_atomic_facts, raw_summary_detailed, raw_summary_extractive, summary_atomic_facts, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37msummary_detailed, summary_prompt\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> columns        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'gen_extractive_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m20\u001b[0m columns        \u001b]8;id=566661;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494641;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'gen_extractive_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> columns        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'gen_extractive_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m20\u001b[0m columns        \u001b]8;id=728397;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=171270;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_extractive_summary <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m10\u001b[0m/\u001b[1;36m18\u001b[0m: parse_extractive_summary \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                   \u001b]8;id=135530;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=701663;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_extractive_summary <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m10\u001b[0m/\u001b[1;36m18\u001b[0m: parse_extractive_summary \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                   \u001b]8;id=310930;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=722396;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">parse_extractive_summary</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: TextParserBlock</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 20</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts, extractive_summary_prompt, </span>      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_summary_extractive</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: summary_extractive</span>                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mparse_extractive_summary\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: TextParserBlock\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 20\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37msummary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts, extractive_summary_prompt, \u001b[0m      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_summary_extractive\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: summary_extractive\u001b[0m                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">parse_extractive_summary - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 2</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 20 → 21</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: summary_extractive</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, raw_atomic_facts, raw_summary_detailed, raw_summary_extractive, summary_atomic_facts, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, summary_extractive, summary_prompt</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mparse_extractive_summary - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 2\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 20 → 21\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: summary_extractive\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, base_document, document, document_outline, document_title, domain, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, raw_atomic_facts, raw_summary_detailed, raw_summary_extractive, summary_atomic_facts, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37msummary_detailed, summary_extractive, summary_prompt\u001b[0m                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_extractive_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> columns      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_extractive_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m21\u001b[0m columns      \u001b]8;id=992659;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=778000;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_extractive_summary'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> columns      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_extractive_summary'\u001b[0m completed successfully: \u001b[1;36m2\u001b[0m samples, \u001b[1;36m21\u001b[0m columns      \u001b]8;id=12779;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=453419;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: melt_summary_columns <span style=\"font-weight: bold\">(</span>MeltColumnsBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m11\u001b[0m/\u001b[1;36m18\u001b[0m: melt_summary_columns \u001b[1m(\u001b[0mMeltColumnsBlock\u001b[1m)\u001b[0m                      \u001b]8;id=936612;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=10929;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: melt_summary_columns <span style=\"font-weight: bold\">(</span>MeltColumnsBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m11\u001b[0m/\u001b[1;36m18\u001b[0m: melt_summary_columns \u001b[1m(\u001b[0mMeltColumnsBlock\u001b[1m)\u001b[0m                      \u001b]8;id=417092;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=180125;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">melt_summary_columns</span><span style=\"color: #000080; text-decoration-color: #000080\"> ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: MeltColumnsBlock</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 2</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 21</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts, extractive_summary_prompt, </span>      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_summary_extractive, summary_extractive</span>                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: summary, dataset_type</span>                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mmelt_summary_columns\u001b[0m\u001b[34m \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: MeltColumnsBlock\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 2\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 21\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, base_document, summary_prompt, raw_summary_detailed, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37msummary_detailed, atomic_facts_prompt, raw_atomic_facts, summary_atomic_facts, extractive_summary_prompt, \u001b[0m      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_summary_extractive, summary_extractive\u001b[0m                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: summary, dataset_type\u001b[0m                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">melt_summary_columns - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 2 → 8</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 21 → 19</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: dataset_type, summary</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">🔴 Removed: base_document, summary_atomic_facts, summary_detailed, summary_extractive</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, raw_atomic_facts, raw_summary_detailed, raw_summary_extractive, summary, summary_prompt</span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mmelt_summary_columns - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 2 → 8\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 21 → 19\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: dataset_type, summary\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[31m🔴 Removed: base_document, summary_atomic_facts, summary_detailed, summary_extractive\u001b[0m                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, raw_atomic_facts, raw_summary_detailed, raw_summary_extractive, summary, summary_prompt\u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'melt_summary_columns'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> columns          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'melt_summary_columns'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m19\u001b[0m columns          \u001b]8;id=194853;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=50345;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'melt_summary_columns'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> columns          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'melt_summary_columns'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m19\u001b[0m columns          \u001b]8;id=189407;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=46606;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: rename_to_document_column <span style=\"font-weight: bold\">(</span>RenameColumnsBlock<span style=\"font-weight: bold\">)</span>               <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m12\u001b[0m/\u001b[1;36m18\u001b[0m: rename_to_document_column \u001b[1m(\u001b[0mRenameColumnsBlock\u001b[1m)\u001b[0m               \u001b]8;id=578228;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=501652;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: rename_to_document_column <span style=\"font-weight: bold\">(</span>RenameColumnsBlock<span style=\"font-weight: bold\">)</span>               <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m12\u001b[0m/\u001b[1;36m18\u001b[0m: rename_to_document_column \u001b[1m(\u001b[0mRenameColumnsBlock\u001b[1m)\u001b[0m               \u001b]8;id=269967;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=972169;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">rename_to_document_column</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: RenameColumnsBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 8</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 19</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed, </span>                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, summary</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: None specified</span>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mrename_to_document_column\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: RenameColumnsBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 8\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 19\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: document, document_outline, document_title, domain, icl_document, icl_query_1, icl_response_1, \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed, \u001b[0m                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, summary\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: None specified\u001b[0m                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">rename_to_document_column - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 8 → 8</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 19 → 19</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_document</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">🔴 Removed: summary</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, raw_atomic_facts, raw_document, raw_summary_detailed, raw_summary_extractive, summary_prompt</span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mrename_to_document_column - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 8 → 8\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 19 → 19\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_document\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[31m🔴 Removed: summary\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, raw_atomic_facts, raw_document, raw_summary_detailed, raw_summary_extractive, summary_prompt\u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'rename_to_document_column'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> columns     <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'rename_to_document_column'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m19\u001b[0m columns     \u001b]8;id=26011;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=877235;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'rename_to_document_column'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> columns     <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'rename_to_document_column'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m19\u001b[0m columns     \u001b]8;id=901006;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=297252;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: knowledge_generation_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>             <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m13\u001b[0m/\u001b[1;36m18\u001b[0m: knowledge_generation_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m             \u001b]8;id=240946;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=308475;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: knowledge_generation_prompt <span style=\"font-weight: bold\">(</span>PromptBuilderBlock<span style=\"font-weight: bold\">)</span>             <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m13\u001b[0m/\u001b[1;36m18\u001b[0m: knowledge_generation_prompt \u001b[1m(\u001b[0mPromptBuilderBlock\u001b[1m)\u001b[0m             \u001b]8;id=42435;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=270152;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">knowledge_generation_prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ──────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: PromptBuilderBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 8</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 19</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document</span>                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: knowledge_generation_prompt</span>                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mknowledge_generation_prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: PromptBuilderBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 8\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 19\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument\u001b[0m                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: knowledge_generation_prompt\u001b[0m                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8/8 [00:00<00:00, 639.30 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">knowledge_generation_prompt - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ─────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 8 → 8</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 19 → 20</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: knowledge_generation_prompt</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, raw_atomic_facts, raw_document, raw_summary_detailed, </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_summary_extractive, summary_prompt</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mknowledge_generation_prompt - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 8 → 8\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 19 → 20\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: knowledge_generation_prompt\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, raw_atomic_facts, raw_document, raw_summary_detailed, \u001b[0m             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_summary_extractive, summary_prompt\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> columns   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'knowledge_generation_prompt'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m20\u001b[0m columns   \u001b]8;id=975511;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=238059;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation_prompt'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> columns   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'knowledge_generation_prompt'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m20\u001b[0m columns   \u001b]8;id=565849;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=395718;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: knowledge_generation <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m14\u001b[0m/\u001b[1;36m18\u001b[0m: knowledge_generation \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                          \u001b]8;id=466471;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=37829;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: knowledge_generation <span style=\"font-weight: bold\">(</span>LLMChatBlock<span style=\"font-weight: bold\">)</span>                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m14\u001b[0m/\u001b[1;36m18\u001b[0m: knowledge_generation \u001b[1m(\u001b[0mLLMChatBlock\u001b[1m)\u001b[0m                          \u001b]8;id=87792;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=928154;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">knowledge_generation</span><span style=\"color: #000080; text-decoration-color: #000080\"> ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: LLMChatBlock</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 8</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 20</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt</span>                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: raw_knowledge_generation</span>                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mknowledge_generation\u001b[0m\u001b[34m \u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: LLMChatBlock\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 8\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 20\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: raw_knowledge_generation\u001b[0m                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m8\u001b[0m samples                                   \u001b]8;id=731635;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=582252;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m8\u001b[0m samples                                   \u001b]8;id=642659;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=217159;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=542544;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=525264;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=329;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104423;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=29552;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=14855;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:31 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=523828;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=858310;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=276791;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=640523;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=120973;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=122701;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=544436;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=914483;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=689986;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=454590;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m8\u001b[0m samples                           \u001b]8;id=727993;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=875722;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples                           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m8\u001b[0m samples                           \u001b]8;id=508341;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=274003;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">knowledge_generation - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 8 → 8</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 20 → 21</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_knowledge_generation</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, raw_atomic_facts, raw_document, raw_knowledge_generation, </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_summary_detailed, raw_summary_extractive, summary_prompt</span>                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mknowledge_generation - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 8 → 8\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 20 → 21\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_knowledge_generation\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, raw_atomic_facts, raw_document, raw_knowledge_generation, \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_summary_detailed, raw_summary_extractive, summary_prompt\u001b[0m                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> columns          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'knowledge_generation'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m21\u001b[0m columns          \u001b]8;id=316955;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=914035;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_generation'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> columns          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'knowledge_generation'\u001b[0m completed successfully: \u001b[1;36m8\u001b[0m samples, \u001b[1;36m21\u001b[0m columns          \u001b]8;id=156191;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=472986;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_knowledge_generation <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                 <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m15\u001b[0m/\u001b[1;36m18\u001b[0m: parse_knowledge_generation \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                 \u001b]8;id=518957;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=663063;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: parse_knowledge_generation <span style=\"font-weight: bold\">(</span>TextParserBlock<span style=\"font-weight: bold\">)</span>                 <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m15\u001b[0m/\u001b[1;36m18\u001b[0m: parse_knowledge_generation \u001b[1m(\u001b[0mTextParserBlock\u001b[1m)\u001b[0m                 \u001b]8;id=330194;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=654858;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">parse_knowledge_generation</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: TextParserBlock</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 8</span>                                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 21</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation</span>                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: question, response</span>                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mparse_knowledge_generation\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: TextParserBlock\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 8\u001b[0m                                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 21\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation\u001b[0m                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: question, response\u001b[0m                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">parse_knowledge_generation - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ─────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 8 → 72</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 21 → 23</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: question, response</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mparse_knowledge_generation - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 8 → 72\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 21 → 23\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: question, response\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mextractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2,\u001b[0m \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, \u001b[0m                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt\u001b[0m                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_knowledge_generation'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> columns   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_knowledge_generation'\u001b[0m completed successfully: \u001b[1;36m72\u001b[0m samples, \u001b[1;36m23\u001b[0m columns   \u001b]8;id=273908;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=727825;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'parse_knowledge_generation'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> columns   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'parse_knowledge_generation'\u001b[0m completed successfully: \u001b[1;36m72\u001b[0m samples, \u001b[1;36m23\u001b[0m columns   \u001b]8;id=155401;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=944368;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: eval_faithfulness <span style=\"font-weight: bold\">(</span>EvaluateFaithfulnessBlock<span style=\"font-weight: bold\">)</span>                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m16\u001b[0m/\u001b[1;36m18\u001b[0m: eval_faithfulness \u001b[1m(\u001b[0mEvaluateFaithfulnessBlock\u001b[1m)\u001b[0m                \u001b]8;id=84353;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803809;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: eval_faithfulness <span style=\"font-weight: bold\">(</span>EvaluateFaithfulnessBlock<span style=\"font-weight: bold\">)</span>                <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m16\u001b[0m/\u001b[1;36m18\u001b[0m: eval_faithfulness \u001b[1m(\u001b[0mEvaluateFaithfulnessBlock\u001b[1m)\u001b[0m                \u001b]8;id=543403;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=59398;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_faithfulness</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: EvaluateFaithfulnessBlock</span>                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 72</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 23</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response</span>                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: faithfulness_explanation, faithfulness_judgment</span>                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_faithfulness\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: EvaluateFaithfulnessBlock\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 72\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 23\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response\u001b[0m                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: faithfulness_explanation, faithfulness_judgment\u001b[0m                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:43:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting faithfulness evaluation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_faithfulness_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#242\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:43:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting faithfulness evaluation for \u001b[1;36m72\u001b[0m samples              \u001b]8;id=911936;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\u001b\\\u001b[2mevaluate_faithfulness_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=337011;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#242\u001b\\\u001b[2m242\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting faithfulness evaluation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_faithfulness_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#242\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting faithfulness evaluation for \u001b[1;36m72\u001b[0m samples              \u001b]8;id=559177;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\u001b\\\u001b[2mevaluate_faithfulness_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=456274;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#242\u001b\\\u001b[2m242\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_faithfulness_prompt_builder</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: PromptBuilderBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 72</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 23</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response</span>                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: eval_faithfulness_prompt</span>                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_faithfulness_prompt_builder\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: PromptBuilderBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 72\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 23\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response\u001b[0m                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: eval_faithfulness_prompt\u001b[0m                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 72/72 [00:00<00:00, 3730.34 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_faithfulness_prompt_builder - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 72 → 72</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 23 → 24</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: eval_faithfulness_prompt</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_response_2, icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_document, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_faithfulness_prompt_builder - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 72 → 72\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 23 → 24\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: eval_faithfulness_prompt\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_1, icl_response_2, icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_document, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_faithfulness_llm_chat</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: LLMChatBlock</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 72</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 24</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt</span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: raw_eval_faithfulness</span>                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_faithfulness_llm_chat\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: LLMChatBlock\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 72\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 24\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt\u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: raw_eval_faithfulness\u001b[0m                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m72\u001b[0m samples                                  \u001b]8;id=25731;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=762186;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m72\u001b[0m samples                                  \u001b]8;id=216469;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=880841;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=842915;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=859259;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=362370;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=226256;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=556046;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=26856;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=734125;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=298974;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=678520;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=941875;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=149671;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=892750;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=461341;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=766355;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=376507;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=643429;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=390783;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=156239;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=519287;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=101752;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=790941;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=228683;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=372186;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=636185;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=978705;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=53864;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=837366;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=8780;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=312996;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=12900;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=528049;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=115623;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=299424;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=333826;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=323388;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=265301;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=461461;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=12245;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=387325;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=75455;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=667831;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=372879;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=864918;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=921352;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=138488;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=598027;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=637913;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=303341;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=403449;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=298677;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=926002;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=506335;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=651337;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=952110;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=608141;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=313102;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=239579;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=430003;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=939052;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=739583;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=753223;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=845953;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=980794;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=958683;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=689690;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=348169;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=343054;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=135252;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=99284;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=74165;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=744324;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=501031;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=19115;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=990249;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=322508;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=57533;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=426808;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=832071;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=773839;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=977934;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=493363;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=109003;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=741657;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104586;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=703190;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=317981;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=583122;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=18127;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=639993;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=365055;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=419308;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=252829;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=52504;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=570972;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=507282;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=890757;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=329067;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=687;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=938139;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=10257;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=410823;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=540163;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=882652;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=730353;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=73754;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=371592;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=179288;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=79567;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=453702;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=181434;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=134922;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=336417;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=740725;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=667251;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=724305;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=783767;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:43:50 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=663370;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=782750;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=222138;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=602779;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=5108;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=248628;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=964137;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=472273;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=764637;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=866181;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=142489;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=322123;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=704568;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=652378;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=682265;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=421205;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=963150;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=37656;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=496362;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464569;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=377753;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=600476;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=312776;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=131079;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=991795;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=948138;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=694128;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=374340;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m72\u001b[0m samples                          \u001b]8;id=722022;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=448474;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> samples                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m72\u001b[0m samples                          \u001b]8;id=900611;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=693484;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_faithfulness_llm_chat - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ─────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 72 → 72</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 24 → 25</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_eval_faithfulness</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_response_2, icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_document, raw_eval_faithfulness, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">response, summary_prompt</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_faithfulness_llm_chat - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 72 → 72\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 24 → 25\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_eval_faithfulness\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, extractive_summary_prompt, icl_document, icl_query_1, icl_query_2, icl_query_3, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_1, icl_response_2, icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_document, raw_eval_faithfulness, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mresponse, summary_prompt\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_faithfulness_text_parser</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: TextParserBlock</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 72</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 25</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: faithfulness_explanation, faithfulness_judgment</span>                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_faithfulness_text_parser\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: TextParserBlock\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 72\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 25\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness\u001b[0m                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: faithfulness_explanation, faithfulness_judgment\u001b[0m                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_faithfulness_text_parser - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 72 → 72</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 25 → 27</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: faithfulness_explanation, faithfulness_judgment</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, extractive_summary_prompt, faithfulness_explanation, faithfulness_judgment, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_faithfulness_text_parser - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m───────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 72 → 72\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 25 → 27\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: faithfulness_explanation, faithfulness_judgment\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, extractive_summary_prompt, faithfulness_explanation, faithfulness_judgment, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mknowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt\u001b[0m                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_faithfulness_filter</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: ColumnValueFilterBlock</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 72</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 27</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment</span>                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: None specified</span>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_faithfulness_filter\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: ColumnValueFilterBlock\u001b[0m                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 72\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 27\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment\u001b[0m                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: None specified\u001b[0m                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 72/72 [00:00<00:00, 4490.16 examples/s]\n",
      "Filter: 100%|██████████| 72/72 [00:00<00:00, 5589.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_faithfulness_filter - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 72 → 71</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 27 → 27</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, extractive_summary_prompt, faithfulness_explanation, faithfulness_judgment, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_faithfulness_filter - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 72 → 71\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 27 → 27\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, extractive_summary_prompt, faithfulness_explanation, faithfulness_judgment, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mknowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt\u001b[0m                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Faithfulness evaluation completed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> → <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_faithfulness_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#254\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Faithfulness evaluation completed: \u001b[1;36m72\u001b[0m → \u001b[1;36m71\u001b[0m samples           \u001b]8;id=773737;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\u001b\\\u001b[2mevaluate_faithfulness_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=352841;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#254\u001b\\\u001b[2m254\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Faithfulness evaluation completed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> → <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples           <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_faithfulness_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#254\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Faithfulness evaluation completed: \u001b[1;36m72\u001b[0m → \u001b[1;36m71\u001b[0m samples           \u001b]8;id=603503;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py\u001b\\\u001b[2mevaluate_faithfulness_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341015;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_faithfulness_block.py#254\u001b\\\u001b[2m254\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_faithfulness - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 72 → 71</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 23 → 27</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: eval_faithfulness_prompt, faithfulness_explanation, faithfulness_judgment, raw_eval_faithfulness</span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, extractive_summary_prompt, faithfulness_explanation, faithfulness_judgment, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_faithfulness - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 72 → 71\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 23 → 27\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: eval_faithfulness_prompt, faithfulness_explanation, faithfulness_judgment, raw_eval_faithfulness\u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, extractive_summary_prompt, faithfulness_explanation, faithfulness_judgment, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, icl_response_3, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mknowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt\u001b[0m                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> columns            <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'eval_faithfulness'\u001b[0m completed successfully: \u001b[1;36m71\u001b[0m samples, \u001b[1;36m27\u001b[0m columns            \u001b]8;id=277414;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=662248;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'eval_faithfulness'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> columns            <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'eval_faithfulness'\u001b[0m completed successfully: \u001b[1;36m71\u001b[0m samples, \u001b[1;36m27\u001b[0m columns            \u001b]8;id=351808;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=75123;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: eval_relevancy <span style=\"font-weight: bold\">(</span>EvaluateRelevancyBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m17\u001b[0m/\u001b[1;36m18\u001b[0m: eval_relevancy \u001b[1m(\u001b[0mEvaluateRelevancyBlock\u001b[1m)\u001b[0m                      \u001b]8;id=439690;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=744824;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: eval_relevancy <span style=\"font-weight: bold\">(</span>EvaluateRelevancyBlock<span style=\"font-weight: bold\">)</span>                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m17\u001b[0m/\u001b[1;36m18\u001b[0m: eval_relevancy \u001b[1m(\u001b[0mEvaluateRelevancyBlock\u001b[1m)\u001b[0m                      \u001b]8;id=113104;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=904730;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_relevancy</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: EvaluateRelevancyBlock</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 71</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 27</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment</span>                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: relevancy_explanation, relevancy_score</span>                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_relevancy\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: EvaluateRelevancyBlock\u001b[0m                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 71\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 27\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment\u001b[0m                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: relevancy_explanation, relevancy_score\u001b[0m                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting relevancy evaluation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples                    <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_relevancy_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#242\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting relevancy evaluation for \u001b[1;36m71\u001b[0m samples                    \u001b]8;id=315365;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\u001b\\\u001b[2mevaluate_relevancy_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=650223;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#242\u001b\\\u001b[2m242\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting relevancy evaluation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples                    <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_relevancy_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#242\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting relevancy evaluation for \u001b[1;36m71\u001b[0m samples                    \u001b]8;id=825615;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\u001b\\\u001b[2mevaluate_relevancy_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=371744;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#242\u001b\\\u001b[2m242\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_relevancy_prompt_builder</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: PromptBuilderBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 71</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 27</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment</span>                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: eval_relevancy_prompt</span>                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_relevancy_prompt_builder\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: PromptBuilderBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 71\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 27\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment\u001b[0m                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: eval_relevancy_prompt\u001b[0m                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 71/71 [00:00<00:00, 2692.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_relevancy_prompt_builder - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 71 → 71</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 27 → 28</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: eval_relevancy_prompt</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_relevancy_prompt_builder - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m───────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 71 → 71\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 27 → 28\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: eval_relevancy_prompt\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, summary_prompt\u001b[0m                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_relevancy_llm_chat</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: LLMChatBlock</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 71</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 28</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt</span>                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: raw_eval_relevancy</span>                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_relevancy_llm_chat\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: LLMChatBlock\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 71\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 28\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt\u001b[0m                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: raw_eval_relevancy\u001b[0m                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m71\u001b[0m samples                                  \u001b]8;id=88744;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494159;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m71\u001b[0m samples                                  \u001b]8;id=264214;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=328561;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=617568;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=687255;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=117580;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=627196;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=481717;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=768634;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=926750;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=310606;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=603336;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=958763;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=672795;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=898770;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=456095;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=282173;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=276173;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=20462;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=452620;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=477001;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=623413;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=192773;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=192298;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=210215;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=223261;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=503218;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=944626;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=850223;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=312932;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=980564;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=446731;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=367273;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=285099;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=85066;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=959983;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=487487;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=659679;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=849174;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=555496;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=712337;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=771872;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=343353;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=715919;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=623131;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=401849;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=697191;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=300408;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=532938;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=371845;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=661959;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=876490;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=340417;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=358385;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=573085;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=886891;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=752820;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=816407;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=204584;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=740909;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=267526;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=867007;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=560462;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=449298;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803286;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=644976;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=638329;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=130950;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=122737;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=21953;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=470805;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=905546;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=174314;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=994168;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=681336;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=157256;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=246882;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=49682;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=164567;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=751969;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=861619;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=194716;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=738044;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=927004;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=141027;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=879072;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=142913;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=643635;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=733419;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=306542;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=867763;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=688198;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=433101;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=256040;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=297832;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=775653;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=30538;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=861466;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=988248;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=673530;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=764633;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=592214;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=468852;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=138428;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=684292;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=179543;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=984395;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=20321;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=270461;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=852729;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=225224;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=188074;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=840923;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=752104;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=928386;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=921178;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=514713;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:03 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=209847;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=565173;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=337160;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=78757;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=890471;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=989324;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=900419;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=222975;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=48987;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=611756;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=464906;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=559161;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=549809;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=791047;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=482730;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=733261;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=337147;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=419892;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=559935;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=667795;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=816630;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=521649;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=357008;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431520;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=959125;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=799103;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=590454;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=221517;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m71\u001b[0m samples                          \u001b]8;id=63182;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=185711;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> samples                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m71\u001b[0m samples                          \u001b]8;id=625168;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=615503;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_relevancy_llm_chat - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 71 → 71</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 28 → 29</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_eval_relevancy</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">summary_prompt</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_relevancy_llm_chat - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 71 → 71\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 28 → 29\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_eval_relevancy\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, response, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37msummary_prompt\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_relevancy_text_parser</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: TextParserBlock</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 71</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 29</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, </span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy</span>                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: relevancy_explanation, relevancy_score</span>                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_relevancy_text_parser\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: TextParserBlock\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 71\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 29\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, \u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_relevancy\u001b[0m                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: relevancy_explanation, relevancy_score\u001b[0m                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_relevancy_text_parser - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ─────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 71 → 71</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 29 → 31</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: relevancy_explanation, relevancy_score</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">relevancy_explanation, relevancy_score, response, summary_prompt</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_relevancy_text_parser - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 71 → 71\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 29 → 31\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: relevancy_explanation, relevancy_score\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mrelevancy_explanation, relevancy_score, response, summary_prompt\u001b[0m                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval_relevancy_filter</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: ColumnValueFilterBlock</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 71</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 31</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, </span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, relevancy_explanation, relevancy_score</span>                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: None specified</span>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34meval_relevancy_filter\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: ColumnValueFilterBlock\u001b[0m                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 71\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 31\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, \u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_relevancy, relevancy_explanation, relevancy_score\u001b[0m                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: None specified\u001b[0m                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 71/71 [00:00<00:00, 3514.19 examples/s]\n",
      "Filter: 100%|██████████| 71/71 [00:00<00:00, 6636.70 examples/s]\n",
      "Filter: 100%|██████████| 71/71 [00:00<00:00, 5435.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_relevancy_filter - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 71 → 62</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 31 → 31</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">relevancy_explanation, relevancy_score, response, summary_prompt</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_relevancy_filter - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m───────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 71 → 62\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 31 → 31\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mrelevancy_explanation, relevancy_score, response, summary_prompt\u001b[0m                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Relevancy evaluation completed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> → <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                 <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_relevancy_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#254\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Relevancy evaluation completed: \u001b[1;36m71\u001b[0m → \u001b[1;36m62\u001b[0m samples                 \u001b]8;id=235654;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\u001b\\\u001b[2mevaluate_relevancy_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=292383;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#254\u001b\\\u001b[2m254\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Relevancy evaluation completed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> → <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                 <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluate_relevancy_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#254\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Relevancy evaluation completed: \u001b[1;36m71\u001b[0m → \u001b[1;36m62\u001b[0m samples                 \u001b]8;id=553459;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py\u001b\\\u001b[2mevaluate_relevancy_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=263698;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/evaluate_relevancy_block.py#254\u001b\\\u001b[2m254\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">eval_relevancy - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 71 → 62</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 27 → 31</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: eval_relevancy_prompt, raw_eval_relevancy, relevancy_explanation, relevancy_score</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">relevancy_explanation, relevancy_score, response, summary_prompt</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32meval_relevancy - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 71 → 62\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 27 → 31\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: eval_relevancy_prompt, raw_eval_relevancy, relevancy_explanation, relevancy_score\u001b[0m                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mrelevancy_explanation, relevancy_score, response, summary_prompt\u001b[0m                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> columns               <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'eval_relevancy'\u001b[0m completed successfully: \u001b[1;36m62\u001b[0m samples, \u001b[1;36m31\u001b[0m columns               \u001b]8;id=616377;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=788261;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'eval_relevancy'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> columns               <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'eval_relevancy'\u001b[0m completed successfully: \u001b[1;36m62\u001b[0m samples, \u001b[1;36m31\u001b[0m columns               \u001b]8;id=937814;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=243763;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: verify_question <span style=\"font-weight: bold\">(</span>VerifyQuestionBlock<span style=\"font-weight: bold\">)</span>                        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m18\u001b[0m/\u001b[1;36m18\u001b[0m: verify_question \u001b[1m(\u001b[0mVerifyQuestionBlock\u001b[1m)\u001b[0m                        \u001b]8;id=161818;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=657856;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing block <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>: verify_question <span style=\"font-weight: bold\">(</span>VerifyQuestionBlock<span style=\"font-weight: bold\">)</span>                        <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">670</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing block \u001b[1;36m18\u001b[0m/\u001b[1;36m18\u001b[0m: verify_question \u001b[1m(\u001b[0mVerifyQuestionBlock\u001b[1m)\u001b[0m                        \u001b]8;id=344655;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=687058;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#670\u001b\\\u001b[2m670\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">verify_question</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: VerifyQuestionBlock</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 62</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 31</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, </span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, relevancy_explanation, relevancy_score</span>                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: verification_explanation, verification_rating</span>                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mverify_question\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: VerifyQuestionBlock\u001b[0m                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 62\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 31\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, \u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_relevancy, relevancy_explanation, relevancy_score\u001b[0m                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: verification_explanation, verification_rating\u001b[0m                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting question verification for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">verify_question_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#248\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting question verification for \u001b[1;36m62\u001b[0m samples                      \u001b]8;id=163354;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\u001b\\\u001b[2mverify_question_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=254519;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#248\u001b\\\u001b[2m248\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting question verification for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                      <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">verify_question_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#248\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting question verification for \u001b[1;36m62\u001b[0m samples                      \u001b]8;id=871938;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\u001b\\\u001b[2mverify_question_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=285020;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#248\u001b\\\u001b[2m248\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">verify_question_prompt_builder</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: PromptBuilderBlock</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 62</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 31</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, </span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, relevancy_explanation, relevancy_score</span>                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: verify_question_prompt</span>                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mverify_question_prompt_builder\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: PromptBuilderBlock\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 62\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 31\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, \u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_relevancy, relevancy_explanation, relevancy_score\u001b[0m                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: verify_question_prompt\u001b[0m                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 62/62 [00:00<00:00, 2620.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">verify_question_prompt_builder - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 62 → 62</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 31 → 32</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: verify_question_prompt</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">relevancy_explanation, relevancy_score, response, summary_prompt, verify_question_prompt</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mverify_question_prompt_builder - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 62 → 62\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 31 → 32\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: verify_question_prompt\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mrelevancy_explanation, relevancy_score, response, summary_prompt, verify_question_prompt\u001b[0m                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">verify_question_llm_chat</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: LLMChatBlock</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 62</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 32</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, </span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, relevancy_explanation, relevancy_score, verify_question_prompt</span>                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: raw_verify_question</span>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mverify_question_llm_chat\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: LLMChatBlock\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 62\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 32\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, \u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_relevancy, relevancy_explanation, relevancy_score, verify_question_prompt\u001b[0m                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: raw_verify_question\u001b[0m                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m62\u001b[0m samples                                  \u001b]8;id=942574;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=164897;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting async generation for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                                  <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting async generation for \u001b[1;36m62\u001b[0m samples                                  \u001b]8;id=476878;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=394895;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=446969;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=674632;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=133820;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=781047;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=938349;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=243558;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=603555;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=478882;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=73655;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=293661;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=838171;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=889195;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=283246;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=852390;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=674726;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=443645;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=877542;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=552347;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=385984;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=342306;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=904319;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=504608;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=490245;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=187214;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=571544;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=442241;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=112524;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=119446;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=662782;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=400475;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n",
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=776294;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=834582;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=427773;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=214728;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=116733;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=879035;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=704474;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=453554;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=695045;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=85611;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=215925;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=32744;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=410523;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=663850;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=938583;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=59920;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=424263;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=738969;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=86268;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=843080;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=113328;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=876738;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=844813;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=849829;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=240303;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=508360;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=802962;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=32530;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=831797;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=538715;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=585766;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=264818;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=646348;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=535511;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=305578;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=90905;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=915145;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=188718;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=880261;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=859999;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=116198;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=425811;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=270220;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=140654;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=720531;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=185232;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=766590;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=792972;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=747941;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=266905;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=466627;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=716069;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=334157;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=280085;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=142790;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=324113;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=503714;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=488113;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=415302;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=649369;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=493143;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=376655;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=744820;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=242305;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=558444;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=686902;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m15:44:16 - LiteLLM:INFO\u001b[0m: utils.py:3293 - \n",
      "LiteLLM completion() model= llama-4-scout-17b-16e-w4a16; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=323605;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=170966;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=335308;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146532;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=242182;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=163207;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=748927;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=521475;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=271532;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=541316;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=409431;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=773803;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=381800;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=622068;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=104570;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=837938;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=372454;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=393959;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=996897;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=414902;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=906528;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=553758;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=929934;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=890395;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=664875;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=213181;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-w4a16; provider = openai        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                                   \u001b]8;id=951564;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=688350;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/litellm/utils.py#3293\u001b\\\u001b[2m3293\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-w4a16; provider = openai        \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m62\u001b[0m samples                          \u001b]8;id=301832;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=490075;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generation completed successfully for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> samples                          <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm_chat_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generation completed successfully for \u001b[1;36m62\u001b[0m samples                          \u001b]8;id=585738;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py\u001b\\\u001b[2mllm_chat_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=641296;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/llm/llm_chat_block.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">verify_question_llm_chat - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ──────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 62 → 62</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 32 → 33</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_verify_question</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, verify_question_prompt</span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mverify_question_llm_chat - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m─────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 62 → 62\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 32 → 33\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_verify_question\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, verify_question_prompt\u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">verify_question_text_parser</span><span style=\"color: #000080; text-decoration-color: #000080\"> ──────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: TextParserBlock</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 62</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 33</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, </span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, relevancy_explanation, relevancy_score, verify_question_prompt, raw_verify_question</span>         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: verification_explanation, verification_rating</span>                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mverify_question_text_parser\u001b[0m\u001b[34m \u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: TextParserBlock\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 62\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 33\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, \u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_relevancy, relevancy_explanation, relevancy_score, verify_question_prompt, raw_verify_question\u001b[0m         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: verification_explanation, verification_rating\u001b[0m                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">verify_question_text_parser - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ─────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 62 → 62</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 33 → 35</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: verification_explanation, verification_rating</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">verification_explanation, verification_rating, verify_question_prompt</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mverify_question_text_parser - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 62 → 62\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 33 → 35\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: verification_explanation, verification_rating\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, \u001b[0m                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mverification_explanation, verification_rating, verify_question_prompt\u001b[0m                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">verify_question_filter</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">📊 Processing Input Data</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Block Type: ColumnValueFilterBlock</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Input Rows: 62</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Input Columns: 35</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Column Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, </span>               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">atomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">document, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, </span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, relevancy_explanation, relevancy_score, verify_question_prompt, raw_verify_question, </span>       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">verification_explanation, verification_rating</span>                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">Expected Output Columns: None specified</span>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mverify_question_filter\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m📊 Processing Input Data\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mBlock Type: ColumnValueFilterBlock\u001b[0m                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36mInput Rows: 62\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mInput Columns: 35\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mColumn Names: raw_document, document_outline, document_title, domain, icl_document, icl_query_1, \u001b[0m               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37micl_response_1, icl_query_2, icl_response_2, icl_query_3, icl_response_3, summary_prompt, raw_summary_detailed,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37matomic_facts_prompt, raw_atomic_facts, extractive_summary_prompt, raw_summary_extractive, dataset_type, \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mdocument, knowledge_generation_prompt, raw_knowledge_generation, question, response, eval_faithfulness_prompt, \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_faithfulness, faithfulness_explanation, faithfulness_judgment, eval_relevancy_prompt, \u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mraw_eval_relevancy, relevancy_explanation, relevancy_score, verify_question_prompt, raw_verify_question, \u001b[0m       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[37mverification_explanation, verification_rating\u001b[0m                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32mExpected Output Columns: None specified\u001b[0m                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 62/62 [00:00<00:00, 2894.49 examples/s]\n",
      "Filter: 100%|██████████| 62/62 [00:00<00:00, 5141.40 examples/s]\n",
      "Filter: 100%|██████████| 62/62 [00:00<00:00, 4421.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">verify_question_filter - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 62 → 47</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 35 → 35</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">verification_explanation, verification_rating, verify_question_prompt</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mverify_question_filter - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 62 → 47\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 35 → 35\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, \u001b[0m                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mverification_explanation, verification_rating, verify_question_prompt\u001b[0m                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Question verification completed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> → <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> samples                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">verify_question_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#260\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Question verification completed: \u001b[1;36m62\u001b[0m → \u001b[1;36m47\u001b[0m samples                   \u001b]8;id=471237;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\u001b\\\u001b[2mverify_question_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=27091;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#260\u001b\\\u001b[2m260\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Question verification completed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> → <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> samples                   <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">verify_question_block.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#260\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Question verification completed: \u001b[1;36m62\u001b[0m → \u001b[1;36m47\u001b[0m samples                   \u001b]8;id=997388;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py\u001b\\\u001b[2mverify_question_block.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=422873;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/blocks/evaluation/verify_question_block.py#260\u001b\\\u001b[2m260\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">verify_question - Complete</span><span style=\"color: #008000; text-decoration-color: #008000\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Processing Complete</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Rows: 62 → 47</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Columns: 31 → 35</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">🟢 Added: raw_verify_question, verification_explanation, verification_rating, verify_question_prompt</span>            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">eval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">faithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">icl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">raw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">verification_explanation, verification_rating, verify_question_prompt</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────────\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mverify_question - Complete\u001b[0m\u001b[32m \u001b[0m\u001b[32m──────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;32m✅ Processing Complete\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mRows: 62 → 47\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[36mColumns: 31 → 35\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[32m🟢 Added: raw_verify_question, verification_explanation, verification_rating, verify_question_prompt\u001b[0m            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37m📋 Final Columns: atomic_facts_prompt, dataset_type, document, document_outline, document_title, domain, \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37meval_faithfulness_prompt, eval_relevancy_prompt, extractive_summary_prompt, faithfulness_explanation, \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mfaithfulness_judgment, icl_document, icl_query_1, icl_query_2, icl_query_3, icl_response_1, icl_response_2, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37micl_response_3, knowledge_generation_prompt, question, raw_atomic_facts, raw_document, raw_eval_faithfulness, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_eval_relevancy, raw_knowledge_generation, raw_summary_detailed, raw_summary_extractive, \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mraw_verify_question, relevancy_explanation, relevancy_score, response, summary_prompt, \u001b[0m                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[37mverification_explanation, verification_rating, verify_question_prompt\u001b[0m                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> columns              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'verify_question'\u001b[0m completed successfully: \u001b[1;36m47\u001b[0m samples, \u001b[1;36m35\u001b[0m columns              \u001b]8;id=23793;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=775700;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Block <span style=\"color: #008000; text-decoration-color: #008000\">'verify_question'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> columns              <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">732</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Block \u001b[32m'verify_question'\u001b[0m completed successfully: \u001b[1;36m47\u001b[0m samples, \u001b[1;36m35\u001b[0m columns              \u001b]8;id=832290;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=705004;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#732\u001b\\\u001b[2m732\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">╭────────── </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\">Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> - </span><span style=\"color: #008000; text-decoration-color: #008000\">Complete</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────╮</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> <span style=\"font-style: italic\">                                       Flow Execution Summary                                        </span>           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> ┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> ┃<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\"> Block Name           </span>┃<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\"> Type            </span>┃<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\">   Duration </span>┃<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\">     Rows     </span>┃<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\">     Columns     </span>┃<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold\">   Status   </span>┃           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> ┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> duplicate_document_… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> DuplicateColum… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.01s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> detailed_summary_pr… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> PromptBuilderB… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.01s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> gen_detailed_summary </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> LLMChatBlock    </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      5.21s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> parse_detailed_summ… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> TextParserBlock </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.02s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> atomic_facts_prompt  </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> PromptBuilderB… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.02s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> gen_atomic_facts     </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> LLMChatBlock    </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      4.58s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> parse_atomic_facts   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> TextParserBlock </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.02s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> extractive_summary_… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> PromptBuilderB… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.02s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> gen_extractive_summ… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> LLMChatBlock    </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      3.69s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> parse_extractive_su… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> TextParserBlock </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.03s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 2     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> melt_summary_columns </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> MeltColumnsBlo… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.04s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    2 → 8     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">      +2/-4      </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> rename_to_document_… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> RenameColumnsB… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.00s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    8 → 8     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">      +1/-1      </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> knowledge_generatio… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> PromptBuilderB… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.02s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    8 → 8     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> knowledge_generation </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> LLMChatBlock    </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">     19.09s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    8 → 8     </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +1        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> parse_knowledge_gen… </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> TextParserBlock </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">      0.03s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">    8 → 72    </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +2        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> eval_faithfulness    </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> EvaluateFaithf… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">     12.72s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">   72 → 71    </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +4        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> eval_relevancy       </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> EvaluateReleva… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">     12.68s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">   71 → 62    </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +4        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> verify_question      </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> VerifyQuestion… </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">     17.47s </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">   62 → 47    </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">       +4        </span>│     <span style=\"color: #008000; text-decoration-color: #008000\">✓</span>      │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> ├──────────────────────┼─────────────────┼────────────┼──────────────┼─────────────────┼────────────┤           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> │<span style=\"color: #00ffff; text-decoration-color: #00ffff\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">TOTAL</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">                </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18 blocks</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">       </span>│<span style=\"color: #ffff00; text-decoration-color: #ffff00\">     </span><span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">75.66s</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\"> </span>│<span style=\"color: #0000ff; text-decoration-color: #0000ff\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold\">47 final</span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">   </span>│<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">    </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">35 final</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">     </span>│   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">18/18</span>    │           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span> └──────────────────────┴─────────────────┴────────────┴──────────────┴─────────────────┴────────────┘           <span style=\"color: #00ff00; text-decoration-color: #00ff00\">│</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m╭─\u001b[0m\u001b[92m─────────\u001b[0m\u001b[92m \u001b[0m\u001b[1;97mAdvanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\u001b[0m\u001b[92m - \u001b[0m\u001b[32mComplete\u001b[0m\u001b[92m \u001b[0m\u001b[92m──────────\u001b[0m\u001b[92m─╮\u001b[0m\n",
       "\u001b[92m│\u001b[0m \u001b[3m                                       Flow Execution Summary                                        \u001b[0m           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m ┃\u001b[1;97m \u001b[0m\u001b[1;97mBlock Name          \u001b[0m\u001b[1;97m \u001b[0m┃\u001b[1;97m \u001b[0m\u001b[1;97mType           \u001b[0m\u001b[1;97m \u001b[0m┃\u001b[1;97m \u001b[0m\u001b[1;97m  Duration\u001b[0m\u001b[1;97m \u001b[0m┃\u001b[1;97m \u001b[0m\u001b[1;97m    Rows    \u001b[0m\u001b[1;97m \u001b[0m┃\u001b[1;97m \u001b[0m\u001b[1;97m    Columns    \u001b[0m\u001b[1;97m \u001b[0m┃\u001b[1;97m \u001b[0m\u001b[1;97m  Status  \u001b[0m\u001b[1;97m \u001b[0m┃           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mduplicate_document_…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mDuplicateColum…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.01s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mdetailed_summary_pr…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mPromptBuilderB…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.01s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mgen_detailed_summary\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mLLMChatBlock   \u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     5.21s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mparse_detailed_summ…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mTextParserBlock\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.02s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96matomic_facts_prompt \u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mPromptBuilderB…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.02s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mgen_atomic_facts    \u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mLLMChatBlock   \u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     4.58s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mparse_atomic_facts  \u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mTextParserBlock\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.02s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mextractive_summary_…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mPromptBuilderB…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.02s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mgen_extractive_summ…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mLLMChatBlock   \u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     3.69s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mparse_extractive_su…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mTextParserBlock\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.03s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 2    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mmelt_summary_columns\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mMeltColumnsBlo…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.04s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   2 → 8    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m     +2/-4     \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mrename_to_document_…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mRenameColumnsB…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.00s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   8 → 8    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m     +1/-1     \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mknowledge_generatio…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mPromptBuilderB…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.02s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   8 → 8    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mknowledge_generation\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mLLMChatBlock   \u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m    19.09s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   8 → 8    \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +1       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mparse_knowledge_gen…\u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mTextParserBlock\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m     0.03s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m   8 → 72   \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +2       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96meval_faithfulness   \u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mEvaluateFaithf…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m    12.72s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m  72 → 71   \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +4       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96meval_relevancy      \u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mEvaluateReleva…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m    12.68s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m  71 → 62   \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +4       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[96mverify_question     \u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[92mVerifyQuestion…\u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m    17.47s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m  62 → 47   \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m      +4       \u001b[0m\u001b[95m \u001b[0m│     \u001b[32m✓\u001b[0m      │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m ├──────────────────────┼─────────────────┼────────────┼──────────────┼─────────────────┼────────────┤           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m │\u001b[96m \u001b[0m\u001b[1;96mTOTAL\u001b[0m\u001b[96m               \u001b[0m\u001b[96m \u001b[0m│\u001b[92m \u001b[0m\u001b[1;92m18 blocks\u001b[0m\u001b[92m      \u001b[0m\u001b[92m \u001b[0m│\u001b[93m \u001b[0m\u001b[93m    \u001b[0m\u001b[1;93m75.66s\u001b[0m\u001b[93m \u001b[0m│\u001b[94m \u001b[0m\u001b[94m  \u001b[0m\u001b[1;94m47 final\u001b[0m\u001b[94m  \u001b[0m\u001b[94m \u001b[0m│\u001b[95m \u001b[0m\u001b[95m   \u001b[0m\u001b[1;95m35 final\u001b[0m\u001b[95m    \u001b[0m\u001b[95m \u001b[0m│   \u001b[1;32m18/18\u001b[0m    │           \u001b[92m│\u001b[0m\n",
       "\u001b[92m│\u001b[0m └──────────────────────┴─────────────────┴────────────┴──────────────┴─────────────────┴────────────┘           \u001b[92m│\u001b[0m\n",
       "\u001b[92m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Flow <span style=\"color: #008000; text-decoration-color: #008000\">'Advanced Document Grounded Question-Answer Generation Flow for Knowledge </span>     <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#620\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">620</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Tuning'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> final samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> final columns                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Flow \u001b[32m'Advanced Document Grounded Question-Answer Generation Flow for Knowledge \u001b[0m     \u001b]8;id=664453;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=240196;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#620\u001b\\\u001b[2m620\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mTuning'\u001b[0m completed successfully: \u001b[1;36m47\u001b[0m final samples, \u001b[1;36m35\u001b[0m final columns                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Flow <span style=\"color: #008000; text-decoration-color: #008000\">'Advanced Document Grounded Question-Answer Generation Flow for Knowledge </span>     <a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#620\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">620</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Tuning'</span> completed successfully: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> final samples, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> final columns                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Flow \u001b[32m'Advanced Document Grounded Question-Answer Generation Flow for Knowledge \u001b[0m     \u001b]8;id=323034;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=227820;file:///Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/02_Knowledge_Generation/.venv/lib/python3.12/site-packages/sdg_hub/core/flow/base.py#620\u001b\\\u001b[2m620\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mTuning'\u001b[0m completed successfully: \u001b[1;36m47\u001b[0m final samples, \u001b[1;36m35\u001b[0m final columns                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate data\n",
    "generated_data = flow.generate(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the generated data into training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=10): 100%|██████████| 47/47 [00:00<00:00, 61.20 examples/s]\n",
      "Map: 100%|██████████| 47/47 [00:00<00:00, 3523.18 examples/s]\n",
      "Map: 100%|██████████| 47/47 [00:00<00:00, 11404.82 examples/s]\n",
      "Filter: 100%|██████████| 47/47 [00:00<00:00, 3899.75 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 2199.62 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 2604.35 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 228.98ba/s]\n",
      "Map (num_proc=10): 100%|██████████| 47/47 [00:00<00:00, 69.00 examples/s]\n",
      "Map: 100%|██████████| 47/47 [00:00<00:00, 3162.21 examples/s]\n",
      "Map: 100%|██████████| 47/47 [00:00<00:00, 6464.20 examples/s]\n",
      "Filter: 100%|██████████| 47/47 [00:00<00:00, 3482.04 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 2146.71 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 376.47ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "312751"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.knowledge_utils import create_knowledge_regular_ds, create_knowledge_pretraining_ds\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "\n",
    "\n",
    "# Create Pretraining Knowledge Dataset (Also known as Phase 0.7/Phase 7)\n",
    "instructlab_phase_1_ds = create_knowledge_pretraining_ds(generated_data)\n",
    "instructlab_phase_1_ds.to_json(f'{OUTPUT_DIR}/instructlab_phase_1_ds.jsonl', orient='records', lines=True)\n",
    "\n",
    "# Create Regular Knowledge Dataset (Also known as Phase 1.0/Phase 10)\n",
    "instructlab_phase_2_ds = create_knowledge_regular_ds(generated_data)\n",
    "\n",
    "# Mix the pre-computed skills with the regular knowledge dataset. If more than one dataset were generated simply add those in this concatenation stage.\n",
    "# If you have any generated instruction data, that can be also mixed in this stage. If you only have generated skills phase 07 generation and training can be skipped.\n",
    "instructlab_phase_2_ds.to_json(f'{OUTPUT_DIR}/instructlab_phase_2_ds.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have any other instruction tuning datasets you can mix with phase 2 dataset.\n",
    "instruction_tuning_dataset_path = \"<Your instruction tuning dataset path>\"\n",
    "instruction_tuning_dataset = load_dataset('json', data_files=instruction_tuning_dataset_path, split='train')\n",
    "instructlab_phase_2_ds = concatenate_datasets([instructlab_phase_2_ds, instruction_tuning_dataset])\n",
    "instructlab_phase_2_ds.to_json(f'{OUTPUT_DIR}/instructlab_phase_2_ds.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02_Knowledge_Generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
