{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "To being, start by installing the SDG Hub examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sdg-hub[examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.knowledge_utils import create_knowledge_regular_ds, create_knowledge_pretraining_ds\n",
    "from pathlib import Path\n",
    "\n",
    "WORKSPACE = Path.cwd().parent # Path to the workspace directory\n",
    "\n",
    "\n",
    "OUTPUT_DIR= WORKSPACE / \"output\" / \"step_02\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True) # Create the output directory if it doesn't exist\n",
    "\n",
    "\n",
    "SEED_DATA_FILE = WORKSPACE / \"output\" / \"step_01\" / \"final_seed_data.jsonl\" # Path to the seed data file generated in step 1\n",
    "\n",
    "\n",
    "if not SEED_DATA_FILE.exists():\n",
    "    raise FileNotFoundError(f\"\\nNot a valid seed data ! {SEED_DATA_FILE}.\\nPlease run step 1 to generate the seed data. \\n(or) Provide the correct path to the seed data file.\")\n",
    "\n",
    "# CONFIGURE MODEL DETAILS HERE FOR THE FLOW\n",
    "MODEL_NAME = \"openai/llama-4-scout-17b-16e-w4a16\"\n",
    "API_KEY = \"\"   # Provide your API key here\n",
    "ENDPOINT = \"https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SDG\n",
    "- This will create knowledge flow from provided yaml file\n",
    "- We will run this on small dataset for demo purposes\n",
    "- For large scale generation, please use the python command provided in the next cell\n",
    "- You can analyze the generated data to ensure the quality is similar to proivded QnA pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover the available generation flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sdg_hub import Flow, FlowRegistry\n",
    "\n",
    "# Required to run the flow with async mode\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  \n",
    "\n",
    "# Auto-discover all available flows (no setup needed!)\n",
    "FlowRegistry.discover_flows()\n",
    "\n",
    "# List available flows\n",
    "flows = FlowRegistry.list_flows()\n",
    "print(f\"Available flows: {flows}\")\n",
    "\n",
    "# You can also search the flows by tag\n",
    "qa_flows = FlowRegistry.search_flows(tag=\"question-generation\")\n",
    "print(f\"QA flows: {qa_flows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\" flow.\n",
    "# For loading the flow simply use the fullname to load it\n",
    "flow_name = \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\"\n",
    "flow_path = FlowRegistry.get_flow_path(flow_name)\n",
    "flow = Flow.from_yaml(flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the recommended model and set the model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.get_default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.get_model_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can dynamically change the model without having to change the flow yaml file.\n",
    "# Configure the flow to use a vllm model hosted at localhost:8000/v1. \n",
    "flow.set_model_config(\n",
    "    model=MODEL_NAME,\n",
    "    api_base=ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seed data\n",
    "number_of_samples = 2\n",
    "\n",
    "ds = load_dataset('json', data_files=f\"{SEED_DATA_FILE}\", split='train')\n",
    "ds = ds.shuffle(seed=42).select(range(number_of_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "generated_data = flow.generate(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the generated data into training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.knowledge_utils import create_knowledge_regular_ds, create_knowledge_pretraining_ds\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "\n",
    "\n",
    "# Create Pretraining Knowledge Dataset (Also known as Phase 0.7/Phase 7)\n",
    "instructlab_phase_1_ds = create_knowledge_pretraining_ds(generated_data)\n",
    "instructlab_phase_1_ds.to_json(f'{OUTPUT_DIR}/instructlab_phase_1_ds.jsonl', orient='records', lines=True)\n",
    "\n",
    "# Create Regular Knowledge Dataset (Also known as Phase 1.0/Phase 10)\n",
    "instructlab_phase_2_ds = create_knowledge_regular_ds(generated_data)\n",
    "\n",
    "# Mix the pre-computed skills with the regular knowledge dataset. If more than one dataset were generated simply add those in this concatenation stage.\n",
    "# If you have any generated instruction data, that can be also mixed in this stage. If you only have generated skills phase 07 generation and training can be skipped.\n",
    "instructlab_phase_2_ds.to_json(f'{OUTPUT_DIR}/instructlab_phase_2_ds.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have any other instruction tuning datasets you can mix with phase 2 dataset.\n",
    "instruction_tuning_dataset_path = \"<Your instruction tuning dataset path>\"\n",
    "instruction_tuning_dataset = load_dataset('json', data_files=instruction_tuning_dataset_path, split='train')\n",
    "instructlab_phase_2_ds = concatenate_datasets([instructlab_phase_2_ds, instruction_tuning_dataset])\n",
    "instructlab_phase_2_ds.to_json(f'{OUTPUT_DIR}/instructlab_phase_2_ds.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02_Knowledge_Generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
