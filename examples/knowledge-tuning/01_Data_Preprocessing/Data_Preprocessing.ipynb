{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4535f5ad",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "You must complete the following pre-processing steps to prepare the `seed.jsonl` dataset for Synthetic Data Generation (SDG). \n",
    "\n",
    "1. Configure the paths\n",
    "2. Load the files into memory\n",
    "3. Convert the document\n",
    "4. Chunk the document\n",
    "5. Generate SDG from randomly selected chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdae2d4",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "-  You need the following information for the model that generates the question and answer pairs:\n",
    "   - An Open AI compatible endpoint\n",
    "   - The model's API key\n",
    "   - The model's name\n",
    "- You can adjust parameters (for example, number of chunks or the QnA prompt).\n",
    "- For large documents or datasets, monitor RAM and disk usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e602c",
   "metadata": {},
   "source": [
    "## Configure the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b27fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "from ai_tools.usecase.knowledge_tuning.create_seed_dataset import \\\n",
    "    get_seed_dataset\n",
    "from ai_tools.usecase.knowledge_tuning.utils import (generate_seed_examples,\n",
    "                                                     review_seed_examples_file,\n",
    "                                                     view_seed_example)\n",
    "\n",
    "WORKSPACE = Path.cwd().parent  # Path to the workspace directory\n",
    "\n",
    "SOURCE_DOCUMENT_DIR = WORKSPACE / \"source_documents\"\n",
    "OUTPUT_DIR = WORKSPACE / \"output\" / \"step_01\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(\n",
    "    parents=True, exist_ok=True\n",
    ")  # Create output directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e67126",
   "metadata": {},
   "source": [
    "## Load the files into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_files = SOURCE_DOCUMENT_DIR.glob(\"**/*.pdf\")\n",
    "available_files = list(available_files)\n",
    "\n",
    "print(f\"Total PDF files found: {len(available_files)} \\n\")\n",
    "print(\"Available Files:\")\n",
    "\n",
    "for file in available_files:\n",
    "    print(f\"\\t{file.stem}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c02fd",
   "metadata": {},
   "source": [
    "## Convert the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82694f1f",
   "metadata": {},
   "source": [
    "The source documents are in PDF format. To chunk the document, you must convert the PDF format to `docling` format.\n",
    "\n",
    "Configure the docling pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PdfPipelineOptions()\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a33fb2",
   "metadata": {},
   "source": [
    "\n",
    "Read and convert the PDF documents to `docling` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960baf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_report = {}\n",
    "for file in available_files:\n",
    "    conv_result = doc_converter.convert(file)\n",
    "\n",
    "    document = conv_result.document\n",
    "    confidence_report[file.stem] = conv_result.confidence\n",
    "\n",
    "    document_dict = document.export_to_dict()\n",
    "\n",
    "    (OUTPUT_DIR / \"docling_output\").mkdir(parents=True, exist_ok=True)\n",
    "    output_file = OUTPUT_DIR / \"docling_output\" / f\"{file.stem}.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(document_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, confidence_report in confidence_report.items():\n",
    "    print(f\"Conversion confidence for {file}:\")\n",
    "\n",
    "    print(\n",
    "        f\"Average confidence: \\x1b[1m{confidence_report.mean_grade.name}\\033[0m (score {confidence_report.mean_score:.3f})\"\n",
    "    )\n",
    "\n",
    "    low_score_pages = []\n",
    "    for page in confidence_report.pages:\n",
    "        page_confidence_report = confidence_report.pages[page]\n",
    "        if page_confidence_report.mean_score < confidence_report.mean_score:\n",
    "            low_score_pages.append(page)\n",
    "\n",
    "    print(\n",
    "        f\"Pages that scored lower than average: {', '.join(str(x + 1) for x in low_score_pages)}\"\n",
    "    )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3178dc",
   "metadata": {},
   "source": [
    "## Chunk the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c0ac9",
   "metadata": {},
   "source": [
    "Run `docling` commands to chunk the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1add96",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = HybridChunker()\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "json_files = (OUTPUT_DIR / \"docling_output\").glob(\"*.json\")\n",
    "\n",
    "convertor = DocumentConverter()\n",
    "\n",
    "for file in json_files:\n",
    "    conv_result = convertor.convert(file)\n",
    "\n",
    "    chunks = chunker.chunk(conv_result.document)\n",
    "    chunks = list(chunks)\n",
    "    print(f\"Total chunks created for {file.stem}: {len(chunks)}\")\n",
    "\n",
    "    for chunk in chunks:\n",
    "        all_chunks.append(\n",
    "            {\n",
    "                \"chunk\": chunker.contextualize(chunk),\n",
    "                \"file\": file.stem,\n",
    "                \"metadata\": chunk.meta.export_json_dict(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "chunks_file_path = OUTPUT_DIR / \"chunks.jsonl\"\n",
    "with open(chunks_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for chunk in all_chunks:\n",
    "        json.dump(chunk, file)\n",
    "        file.write(\"\\n\")\n",
    "    print(f\"Path of chunks JSON is: {Path(chunks_file_path).resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bfb8d",
   "metadata": {},
   "source": [
    "View a random sample of chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHUNKS_TO_VIEW = 5\n",
    "\n",
    "\n",
    "sample = random.sample(all_chunks, min(len(all_chunks), NUM_CHUNKS_TO_VIEW))\n",
    "\n",
    "i = 1\n",
    "for chunk in sample:\n",
    "    print(f\"== Randomly selected chunk {i}: ==========\\n\\n{chunk['chunk']}\\n\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179f5f6",
   "metadata": {},
   "source": [
    "Read the chunks from the saved file and then randomly select the chunks to use as seed data for SDG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e275e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "with open(chunks_file_path, encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        chunk = json.loads(line)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "NUM_SEED_EXAMPLES = 5  # Number of chunks to select as seed examples\n",
    "selected_chunks = random.sample(chunks, NUM_SEED_EXAMPLES)\n",
    "selected_chunks_path = OUTPUT_DIR / \"selected_chunks.jsonl\"\n",
    "with open(selected_chunks_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for chunk in selected_chunks:\n",
    "        json.dump(chunk, file)\n",
    "        file.write(\"\\n\")\n",
    "    print(f\"Path of selected chunks JSON is: {Path(selected_chunks_path).resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6682e",
   "metadata": {},
   "source": [
    "## Generate question and answer data for each chunk\n",
    "\n",
    "Edit the values in the next cell by entering the following information for the model that generates the question and answer pairs:\n",
    "   - The model's API key\n",
    "   - An Open AI compatible endpoint\n",
    "   - The model's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1899f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your API credentials and model details\n",
    "API_KEY = \"\"  # Replace with your actual API key\n",
    "ENDPOINT = \"https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1\"\n",
    "MODEL_NAME = \"granite-3-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ae568",
   "metadata": {},
   "source": [
    "For each selected chunk, generate question and answer (QnA) data and save it to a `QnA.yaml` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f617e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOMISATION_PROMPT = \"Generate atleast 5 seed examples in the format specified below.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd160498",
   "metadata": {},
   "source": [
    "For each randomly selected chunk, create a QnA pair in the `QnA.yaml` file. \n",
    "\n",
    "To generate the QnA pair, use a LLM with a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ffc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_seed_examples(\n",
    "    \"\",\n",
    "    selected_chunks_path,\n",
    "    OUTPUT_DIR,\n",
    "    API_KEY,\n",
    "    ENDPOINT,\n",
    "    MODEL_NAME,\n",
    "    \"DOMAIN\",\n",
    "    \"SUMMARY\",\n",
    "    CUSTOMISATION_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13b5cd",
   "metadata": {},
   "source": [
    "View a seed example from the generated `QnA.yaml` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bf167",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_seed_example(OUTPUT_DIR / \"qna.yaml\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efbea8",
   "metadata": {},
   "source": [
    "Review the generated QnA pairs:\n",
    "\n",
    "- Check for the presence of required fields.\n",
    "- Check the number of seed examples generated.\n",
    "- Check the number of QnA pairs generated for each seed example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_seed_examples_file(OUTPUT_DIR / \"qna.yaml\", min_seed_examples=4, num_qa_pairs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_data = get_seed_dataset(OUTPUT_DIR, OUTPUT_DIR)\n",
    "seed_data\n",
    "seed_data.to_json(OUTPUT_DIR / \"final_seed_data.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489a08d",
   "metadata": {},
   "source": [
    "\n",
    "## Next Step\n",
    "\n",
    "[Synthetic Data Processing](../02_Knowledge_Generation/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01_Data_Preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
