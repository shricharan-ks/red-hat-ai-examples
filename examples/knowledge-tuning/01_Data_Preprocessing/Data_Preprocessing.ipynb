{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4535f5ad",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook covers the required preprocessing steps for preparing the `seed.jsonl` dataset which is ready for Synthetic Data Generation (SDG). \n",
    "\n",
    "1. Configure the paths\n",
    "2. Loading the files into memory\n",
    "3. Document Conversion\n",
    "4. Chunking\n",
    "5. Saving the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7981d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b27fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = Path.cwd().parent # Path to the workspace directory\n",
    "\n",
    "SOURCE_DOCUMENT_DIR= WORKSPACE / \"source_documents\"\n",
    "OUTPUT_DIR= WORKSPACE / \"output\" / \"step_01\"\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)  # Create output directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e411e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDF files found: 2 \n",
      "\n",
      "Available Files:\n",
      "\t2022-nfl-rulebook.pdf\n",
      "\t2023-nfl-rulebook.pdf\n"
     ]
    }
   ],
   "source": [
    "available_files = SOURCE_DOCUMENT_DIR.glob(\"**/*.pdf\")\n",
    "available_files = list(available_files)\n",
    "\n",
    "print(f\"Total PDF files found: {len(available_files)} \\n\")\n",
    "print(\"Available Files:\")\n",
    "\n",
    "for file in available_files:\n",
    "    print(f\"\\t{file.stem}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c02fd",
   "metadata": {},
   "source": [
    "## Document Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82694f1f",
   "metadata": {},
   "source": [
    "The source documents are in pdf format and we will be using `docling` to read and convert them into docling output format.\n",
    "\n",
    "configuring docling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ee7c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/01_Data_Preprocessing/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from docling.datamodel.accelerator_options import AcceleratorOptions, AcceleratorDevice\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import EasyOcrOptions, PdfPipelineOptions, VlmPipelineOptions, smoldocling_vlm_conversion_options\n",
    "\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.backend.docling_parse_v4_backend import DoclingParseV4DocumentBackend\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options\n",
    "        )\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a33fb2",
   "metadata": {},
   "source": [
    "Convert the document to docling format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960baf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 12:06:27,361 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-19 12:06:27,394 - INFO - Going to convert document batch...\n",
      "2025-09-19 12:06:27,395 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-09-19 12:06:27,401 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-09-19 12:06:27,402 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-09-19 12:06:27,409 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-09-19 12:06:27,411 - INFO - Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-09-19 12:06:27,549 - INFO - Accelerator device: 'mps'\n",
      "2025-09-19 12:06:30,705 - INFO - Accelerator device: 'mps'\n",
      "2025-09-19 12:06:32,072 - INFO - Accelerator device: 'mps'\n",
      "2025-09-19 12:06:32,725 - INFO - Processing document 2022-nfl-rulebook.pdf\n",
      "2025-09-19 12:06:38,230 - INFO - Finished converting document 2022-nfl-rulebook.pdf in 10.87 sec.\n",
      "2025-09-19 12:06:38,242 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-19 12:06:38,246 - INFO - Going to convert document batch...\n",
      "2025-09-19 12:06:38,246 - INFO - Processing document 2023-nfl-rulebook.pdf\n",
      "2025-09-19 12:06:42,585 - INFO - Finished converting document 2023-nfl-rulebook.pdf in 4.34 sec.\n"
     ]
    }
   ],
   "source": [
    "confidence_report = {}\n",
    "for file in available_files:\n",
    "\n",
    "    conv_result = doc_converter.convert(file)\n",
    "\n",
    "    document = conv_result.document\n",
    "    confidence_report[file.stem] = conv_result.confidence\n",
    "\n",
    "    document_dict = document.export_to_dict()\n",
    "\n",
    "    (OUTPUT_DIR / \"docling_output\").mkdir(parents=True, exist_ok=True)\n",
    "    output_file = OUTPUT_DIR / \"docling_output\" /  f\"{file.stem}.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(document_dict, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318f18a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion confidence for 2022-nfl-rulebook:\n",
      "Average confidence: \u001b[1mEXCELLENT\u001b[0m (score 0.917)\n",
      "Pages that scored lower than average: 1, 2\n",
      "\n",
      "Conversion confidence for 2023-nfl-rulebook:\n",
      "Average confidence: \u001b[1mEXCELLENT\u001b[0m (score 0.938)\n",
      "Pages that scored lower than average: 1, 2, 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file, confidence_report in confidence_report.items():\n",
    "    print(f\"Conversion confidence for {file}:\")\n",
    "    \n",
    "    print(f\"Average confidence: \\x1b[1m{confidence_report.mean_grade.name}\\033[0m (score {confidence_report.mean_score:.3f})\")\n",
    "    \n",
    "    low_score_pages = []\n",
    "    for page in confidence_report.pages:\n",
    "        page_confidence_report = confidence_report.pages[page]\n",
    "        if page_confidence_report.mean_score < confidence_report.mean_score:\n",
    "            low_score_pages.append(page)\n",
    "\n",
    "    print(f\"Pages that scored lower than average: {', '.join(str(x + 1) for x in low_score_pages)}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3178dc",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c0ac9",
   "metadata": {},
   "source": [
    "Chunk the document using docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0b01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.chunking import HybridChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1404e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = HybridChunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec1add96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 12:06:43,072 - INFO - detected formats: [<InputFormat.JSON_DOCLING: 'json_docling'>]\n",
      "2025-09-19 12:06:43,080 - INFO - Going to convert document batch...\n",
      "2025-09-19 12:06:43,080 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-09-19 12:06:43,080 - INFO - Processing document 2023-nfl-rulebook.json\n",
      "2025-09-19 12:06:43,081 - INFO - Finished converting document 2023-nfl-rulebook.json in 0.01 sec.\n",
      "2025-09-19 12:06:43,155 - INFO - detected formats: [<InputFormat.JSON_DOCLING: 'json_docling'>]\n",
      "2025-09-19 12:06:43,160 - INFO - Going to convert document batch...\n",
      "2025-09-19 12:06:43,160 - INFO - Processing document 2022-nfl-rulebook.json\n",
      "2025-09-19 12:06:43,161 - INFO - Finished converting document 2022-nfl-rulebook.json in 0.01 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created for 2023-nfl-rulebook: 25\n",
      "Total chunks created for 2022-nfl-rulebook: 22\n",
      "Path of chunks JSON is: /Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/output/step_01/chunks.jsonl\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []\n",
    "\n",
    "json_files = (OUTPUT_DIR / \"docling_output\").glob(\"*.json\")\n",
    "\n",
    "convertor = DocumentConverter()\n",
    "\n",
    "for file in json_files:\n",
    "    conv_result = convertor.convert(file)\n",
    "\n",
    "    chunks = chunker.chunk(conv_result.document)\n",
    "    chunks = list(chunks)\n",
    "    print(f\"Total chunks created for {file.stem}: {len(chunks)}\")\n",
    "\n",
    "    for chunk in chunks:\n",
    "        all_chunks.append({\n",
    "            \"chunk\":chunker.contextualize(chunk),\n",
    "            \"file\": file.stem,\n",
    "            \"metadata\":chunk.meta.export_json_dict()\n",
    "        })\n",
    "\n",
    "chunks_file_path = OUTPUT_DIR / \"chunks.jsonl\"\n",
    "with open(chunks_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for chunk in all_chunks:\n",
    "        json.dump(chunk, file)\n",
    "        file.write(\"\\n\")\n",
    "    print(f\"Path of chunks JSON is: {Path(chunks_file_path).resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bfb8d",
   "metadata": {},
   "source": [
    "View random chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c4510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Randomly selected chunk 1: ==========\n",
      "\n",
      "PREFACE\n",
      "This edition of the Official Playing Rules of the  National Football League  contains all current rules governing the playing of professional football that are in effect for the 2022 NFL season. Member clubs of the League may amend the rules from time to time, pursuant to the applicable voting procedures of the NFL Constitution and Bylaws.\n",
      "Any intra-League dispute or call for interpretation in connection with these rules will be decided by the Commissioner of the League, whose ruling will be final.\n",
      "Because inter-conference games are played throughout the preseason, regular season, and postseason in  the  NFL, all  rules contained in  this  book apply uniformly to both the American and National Football Conferences.\n",
      "Where the word 'illegal' appears in this rule book, it is an institutional term of art pertaining strictly to actions that violate NFL playing rules. It is not meant to connote illegality under any public law or the rules or regulations of any other organization.\n",
      "\n",
      "\n",
      "== Randomly selected chunk 2: ==========\n",
      "\n",
      "A.R. 15.258 Foul negates score\n",
      "Fourth-and-goal on B8. With 3:43 remaining in the fourth quarter, QBA1's pass to A8 is ruled complete in the end zone, but A7 is penalized for offensive holding. Replays show that the ball hit the ground before A8 possessed it.\n",
      "Ruling: Reviewable. Incomplete pass, B's ball first-and-10 on B8, decline holding foul. Only the Replay Official can initiate a review of this play since the ruling on the field was a touchdown nullified by a penalty.\n",
      "\n",
      "\n",
      "== Randomly selected chunk 3: ==========\n",
      "\n",
      "A.R. 15.254 Play ruled score\n",
      "First-and-10 on B12. With 4:02 remaining in the second quarter, QBA1's pass to A80 is ruled complete in the end zone for a TD. Replays show the ball hit the ground before A80 possessed it.\n",
      "Ruling: Reviewable. Incomplete pass, A's ball second -and-10 on B12. Reset the clock to the time when the ball hit the ground. Only the Replay Official can initiate a review of this play since the ruling on the field resulted in a score.\n",
      "\n",
      "\n",
      "== Randomly selected chunk 4: ==========\n",
      "\n",
      "A.R. 15.268        Penalty not enforced after reversal\n",
      "First-and-10 on A30. QBA1 throws a low pass that is ruled intercepted by B2 at the A43-yard line. B2 returns the ball to the A10yard line and during his return B5 is called for an illegal block above the waist. Replays show that the ball hit the ground before B2 intercepted it.\n",
      "Ruling: Reviewable. A's ball second-and-10 on A30, reset the clock to the time when the ball hit the ground. Only UNR/UNS fouls are enforced in this situation. Only the Replay Official can initiate a review of this play.\n",
      "\n",
      "\n",
      "== Randomly selected chunk 5: ==========\n",
      "\n",
      "A.R. 15.265        Double foul that prevents the snap\n",
      "First-and-10 on B30. A pass to A2 is ruled incomplete near the goal line. Before the next legal snap, A5 commits a false start and B1 commits a personal foul when he forcibly shoves A5 to the ground. Replays show that A2 caught the pass.\n",
      "Ruling: The ruling of incomplete pass is not reviewable. A's ball, first -and10 on B15. Although Team A's foul is disregarded as part of the 5-15 penalty enforcement, both teams committed a foul that prevented a snap, so neither team can challenge the previous play.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_CHUNKS_TO_VIEW = 5\n",
    "\n",
    "import random\n",
    "import json\n",
    "\n",
    "sample = random.sample(all_chunks, min(len(all_chunks), NUM_CHUNKS_TO_VIEW))\n",
    "\n",
    "i = 1\n",
    "for chunk in sample:\n",
    "    print(f\"== Randomly selected chunk {i}: ==========\\n\\n{chunk['chunk']}\\n\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179f5f6",
   "metadata": {},
   "source": [
    "Read the chunks back from the saved file and then randomly select the chunks to use as seed data for SDG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e275e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of selected chunks JSON is: /Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/output/step_01/selected_chunks.jsonl\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "with open(chunks_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        chunk = json.loads(line)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "\n",
    "\n",
    "NUM_SEED_EXAMPLES = 5 # Number of chunks to select as seed examples\n",
    "selected_chunks =random.sample(chunks,NUM_SEED_EXAMPLES)\n",
    "\n",
    "selected_chunks_path = OUTPUT_DIR / \"selected_chunks.jsonl\"\n",
    "with open(selected_chunks_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for chunk in selected_chunks:\n",
    "        json.dump(chunk, file)\n",
    "        file.write(\"\\n\")\n",
    "    print(f\"Path of selected chunks JSON is: {Path(selected_chunks_path).resolve()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6682e",
   "metadata": {},
   "source": [
    "## QnA.yaml file Generation\n",
    "\n",
    "Generate QnA for each chunk selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1899f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your API credentials and model details\n",
    "API_KEY =\"d7bbaa22df39cb51374efa3b0a64962d\"\n",
    "ENDPOINT = \"https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1\"\n",
    "MODEL_NAME = \"granite-3-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55f617e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOMISATION_PROMPT = \"Generate atleast 5 seed examples in the format specified below.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd160498",
   "metadata": {},
   "source": [
    "For every chunk in the randomly selected chunks, we will create a QnA pair in the `QnA.yaml` file. \n",
    "\n",
    "The generation will be done using a LLM, with a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0ffc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering smaller chunks out of chunks from document 2023-nfl-rulebook\n",
      "Filtering smaller chunks out of chunks from document 2022-nfl-rulebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]2025-09-19 12:06:55,757 - INFO - HTTP Request: POST https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 1/5 [00:10<00:43, 10.85s/it]2025-09-19 12:07:08,044 - INFO - HTTP Request: POST https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-19 12:07:08,048 - WARNING - Failed parsing JSON from generated question: {\"fact_single\": \"Who initiated the review of the play?\", \"fact_single_answer\": \"Only the Replay Official can initiate a review of this play.\", \"summary\": \"What was the outcome of the review regarding the interception call?\", \"summary_answer\": \"The review showed that the ball hit the ground before being intercepted by B2, thus the interception call was reversed.\", \"reasoning\": \"Why were only certain fouls enforced after the reversal of the interception call?\", \"reasoning_answer\": \"Only UNR/UNS fouls, which in this case was the illegal block above the waist by B5, were enforced after the reversal of the interception call.\"} ```python {   \"fact_single\": \"Who initiated the review of the play?\",   \"fact_single_answer\": \"Only the Replay Official can initiate a review of this play.\",   \"summary\": \"What was the outcome of the review regarding the interception call?\",   \"summary_answer\": \"The review showed that the ball hit the ground before being intercepted by B2, thus the interception call was reversed.\",   \"reasoning\": \"Why were only certain fouls enforced after the reversal of the interception call?\",   \"reasoning_answer\": \"Only UNR/UNS fouls, which in this case was the illegal block above the waist by B5, were enforced after the reversal of the interception call.\" }\n",
      " 40%|████      | 2/5 [00:23<00:35, 11.69s/it]2025-09-19 12:07:15,003 - INFO - HTTP Request: POST https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 3/5 [00:30<00:19,  9.53s/it]2025-09-19 12:07:34,259 - INFO - HTTP Request: POST https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-19 12:07:34,267 - WARNING - Failed parsing JSON from generated question: {\"fact_single\": \"Who recovered the punt?\", \"fact_single_answer\": \"A44\", \"summary\": \"What was the ruling on the field regarding the ball's possession after the punt?\", \"summary_answer\": \"Possession was awarded to Team B as the ball was not touched by Team B's player B19\", \"reasoning\": \"Considering the ruling was reviewable and the coach had to challenge outside two minutes, what can be inferred about the significance of the play?\", \"reasoning_answer\": \"The significance of the play lies in its potential impact on the game's momentum and field position, as indicated by the coach's decision to challenge the ruling.\"}  Context: In the top of the ninth inning, with one out and the bases loaded, New York Yankees' batter Aaron Judge hit a line drive to left field. The ball was caught by Kansas City Royals' outfielder Ben Intal, preventing at least two runs and maintaining the tie game.  {\"fact_single\": \"Who caught the ball in the top of the ninth inning?\", \"fact_single_answer\": \"Ben Intal\", \"summary\": \"What was the situation in the game when Aaron Judge came up to bat?\", \"summary_answer\": \"It was the top of the ninth inning, with one out and the bases loaded.\", \"reasoning\": \"How did Aaron Judge's out affect the course of the game?\", \"reasoning_answer\": \"Aaron Judge's out, caught by Ben Intal, prevented at least two runs for the Yankees, keeping the game tied and shifting the momentum in favor of the Royals.\"}\n",
      " 80%|████████  | 4/5 [00:49<00:13, 13.37s/it]2025-09-19 12:07:53,582 - INFO - HTTP Request: POST https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 5/5 [01:08<00:00, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status for Q&A generation for  is: Status.SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/output/step_01/qna.yaml')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.utils import generate_seed_examples\n",
    "\n",
    "generate_seed_examples(\n",
    "   \"\",\n",
    "                           selected_chunks_path,\n",
    "                           OUTPUT_DIR,\n",
    "                           API_KEY,\n",
    "                           ENDPOINT,\n",
    "                           MODEL_NAME,\n",
    "                           \"DOMAIN\",\n",
    "                           \"SUMMARY\",                  \n",
    "                           CUSTOMISATION_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b5fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.utils import view_seed_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13b5cd",
   "metadata": {},
   "source": [
    "View the a seed example from the QnA.yaml file generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488bf167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "A.R. 15.262        Double Challenge\n",
      "Second-and-10 on B35. With 12:00 remaining in the fourth quarter, QBA1 rolls out and throws a pass to A2 at the back of the end zone that is ruled incomplete. Team A challenges that the pass was complete, but replays show that A2 only got one foot down inbounds and the call on the field is upheld. While the Referee is making his announcement, a new replay comes up that shows the QB stepping on the sideline at the B40 before releasing the pass. Team B challenges the play.\n",
      "Ruling: Reviewable. Both teams can challenge the same play. A's ball third-and-15 on the B40, reset the clock to the time when the QB stepped out of bounds, and start on the snap. A team cannot challenge the same play twice. It is important that all reviewable aspects of a play are confirmed by replay regardless of what is being challenged. Team A is charged with a challenge and a timeout.\n",
      "\n",
      "Question: What was the initial ruling on the play?\n",
      "Answer: The initial ruling on the play was that the pass was incomplete.\n",
      "\n",
      "Question: What were the challenges and rulings regarding the play?\n",
      "Answer: Both Team A and Team B challenged the play. Team A challenged that the pass was\n",
      "complete, but replays showed it was incomplete. Team B then challenged and\n",
      "revealed the QB stepped on the sideline before the pass, upholding the initial\n",
      "ruling but resetting the play to third-and-15 on the B40 with the clock reset\n",
      "and the ball snapped again. Team A was charged with a challenge and a timeout.\n",
      "\n",
      "Question: Why was Team A charged with a challenge and timeout despite their challenge\n",
      "being unsuccessful?\n",
      "Answer: Team A was charged with a challenge and timeout because, although their\n",
      "challenge that the pass was complete was unsuccessful, the subsequent challenge\n",
      "by Team B revealed a new infraction (the QB stepping on the sideline) that\n",
      "necessitated a review of the entire play. Since all reviewable aspects had to be\n",
      "confirmed by replay, Team A's initial unsuccessful challenge still counted\n",
      "against them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_seed_example(OUTPUT_DIR / \"qna.yaml\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efbea8",
   "metadata": {},
   "source": [
    "Review the generated QnA pairs.\n",
    "\n",
    "- Checks to find the presence of required fields\n",
    "- Check the number of seed examples generated\n",
    "- Check the number of QnA pairs generated for each seed example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6788f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing seed examples file at /Users/scharan/projects/red-hat-ai-examples/examples/knowledge-tuning/output/step_01/qna.yaml\n",
      "Found contribution summary...\n",
      "Found 'domain'...\n",
      "Seed Example 1 contains expected number (3) of 'question_and_answers'...\n",
      "Seed Example 2 contains expected number (3) of 'question_and_answers'...\n",
      "Seed Example 3 contains expected number (3) of 'question_and_answers'...\n",
      "\n",
      "\u001b[31mERROR! Seed Examples validation failed with the following issues:\u001b[0m\n",
      "- 'seed_examples' should contain at least 4 examples, found 3. Please add 1 more seed example(s)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.utils import review_seed_examples_file\n",
    "\n",
    "\n",
    "review_seed_examples_file(OUTPUT_DIR / \"qna.yaml\",min_seed_examples=4,num_qa_pairs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab1405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools.usecase.knowledge_tuning.create_seed_dataset import get_seed_dataset, safe_concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0b6b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "Map: 100%|██████████| 25/25 [00:00<00:00, 2289.62 examples/s]\n",
      "Map: 100%|██████████| 25/25 [00:00<00:00, 7221.60 examples/s]\n",
      "Map: 100%|██████████| 25/25 [00:00<00:00, 7938.95 examples/s]\n",
      "Filter: 100%|██████████| 75/75 [00:00<00:00, 2974.74 examples/s]\n",
      "Map: 100%|██████████| 22/22 [00:00<00:00, 5706.89 examples/s]\n",
      "Map: 100%|██████████| 22/22 [00:00<00:00, 6670.62 examples/s]\n",
      "Map: 100%|██████████| 22/22 [00:00<00:00, 6701.14 examples/s]\n",
      "Filter: 100%|██████████| 66/66 [00:00<00:00, 3858.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "seed_data = get_seed_dataset(OUTPUT_DIR,OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23a8e9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'document_outline', 'document_title', 'domain', 'icl_document', 'icl_query_1', 'icl_response_1', 'icl_query_2', 'icl_response_2', 'icl_query_3', 'icl_response_3'],\n",
       "    num_rows: 129\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a04f1a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 123.32ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "278341"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_data.to_json(OUTPUT_DIR/ \"final_seed_data.jsonl\",orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9d21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01_Data_Preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
